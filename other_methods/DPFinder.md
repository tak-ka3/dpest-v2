DP-Finder: サンプリングと最適化による差分プライバシー違反検出
差分プライバシーの違反定義と最適化問題の定式化

差分プライバシー (Differential Privacy, DP) では、任意の2つの隣接入力 $x, x'$ に対し、アルゴリズム $F(x)$ の出力分布が近接するようにノイズ付加を行います。形式的には、$F: X \to Y$ が $\epsilon$-DP であるとは、「任意の隣接入力対 $(x, x') \in \mathit{Neigh}$ と任意の出力事象 $\Phi \subseteq Y$ について、$F(x)$ が $\Phi$ に入る確率と $F(x')$ が $\Phi$ に入る確率の比が $\exp(\epsilon)$ により有界である」ことを意味します。すなわち不等式で表すと以下が成立します。

Pr[F(x)∈Φ]≤exp(ϵ)Pr[F(x′)∈Φ].

本研究では入力空間 $X$ は実ベクトル空間 ($X=\mathbb{R}^k$) を想定し、出力空間 $Y$ は実ベクトルか有限離散集合のベクトルとしています。データベース応用では典型的に「隣接関係 $\mathit{Neigh}$」は、2つの入力ベクトルが各成分で高々1だけ異なる（すなわちユーザ1人分のデータ差に対応）場合と定義できます。

あるアルゴリズムが$\epsilon$-DPでない（違反している）ことを示すには、その反例 (counterexample) を見つける必要があります。それは「ある隣接入力ペア $(x, x')$ とある出力集合 $\Phi$」の組であって、上記の$\epsilon$-DP不等式を満たさないもの、すなわち

Pr[F(x)∈Φ]>exp(ϵ)Pr[F(x′)∈Φ]

となるものです。この条件は、$\Pr[F(x') \in \Phi]$ が0でないと仮定すれば、対数をとることで以下と同値です。

\epsilon < \log \frac{\Pr[F(x) \in \Phi]}{\Pr[F(x') \in \Phi]} \,. \tag{1}

プライバシー違反度 $\epsilon(x,x',\Phi)$ は、与えられた候補反例 $(x,x',\Phi)$ に対しこの不等式(1)を満たす最大の値として定義されます。実際には不等式が成り立つ限り右辺の対数比を越える任意の$\epsilon$が違反となり得るため、その上限として**$\epsilon(x,x',\Phi) := \log \frac{\Pr[F(x)\in\Phi]}{\Pr[F(x')\in\Phi]}$**と定義できます。これは単に$\Pr[F(x)\in\Phi]$と$\Pr[F(x')\in\Phi]$の確率比の対数です。

DP-Finderの目標は、「できるだけ大きな違反度 $\epsilon(x,x',\Phi)$ を示す反例 $(x,x',\Phi)$ を見つける」ことです。すなわち最悪の（最大の）プライバシー漏洩を起こす入力ペアと出力集合を探索します。この課題は次の最適化問題として定式化されます。

max	​ϵ(x,x′,Φ). s.t.(x,x′)∈Neigh.(3)

上記問題は困難です。直接的なアプローチとしては、まず**(i)** 任意の$x,x',\Phi$に対して確率 $\Pr[F(x)\in\Phi]$ と $\Pr[F(x')\in\Phi]$ を正確に計算し、(ii) その比の対数を解析的に最大化する、という方法が考えられます。しかし著者らが試みたところ、確率の記号的計算には PSI などのツールを用いても計算量が大きく、さらに最大化問題も数式処理ソフト（Mathematica）では単純な場合ですら解けませんでした。例えば配列サイズ2の簡単なアルゴリズムでさえ6時間計算しても解が得られず、配列サイズ4ではPSIによる確率計算も6時間でタイムアウトしたと報告されています。したがって、この直接解法は実用的でなく、DP-Finderでは別のアプローチが提案されています。

DP-Finderの手法概要

DP-Finderは上記の難解な最適化問題(3)を解決するために、サンプリングと数値最適化の二段階からなる戦略を取ります。その概要は次のとおりです。

(1) 違反度の確率的推定: 確率 $\Pr[F(x)\in\Phi]$ などを解析的に求める代わりに、モンテカルロサンプリングにより推定します。推定精度を評価するため、サンプリング結果から信頼区間（誤差範囲）を算出し、十分に精度が高まるまでサンプル数を増加させます。この際、相関サンプリング (correlated sampling) と呼ばれる工夫により、$x$側と$x'$側のサンプルに同じ乱数を対応させることで分散を低減します。こうして各候補$(x,x',\Phi)$に対し推定違反度 $\hat{\epsilon}(x,x',\Phi)$ を得ます。

(2) 微分可能な目的関数への置換: 上記の推定違反度 $\hat{\epsilon}(x,x',\Phi)$ は一般に確率的な分岐を含むため非連続・非微分可能です。そのままでは勾配法による最適化に適さないため、滑らかな近似関数 $\hat{\epsilon}_d(x,x',\Phi)$ へと変換します。具体的には、確率チェックの判定処理（ブール条件式やif文）を滑らかな関数で近似し、すべての演算が微分可能となるようプログラムを書き換えます。この変換後の $\hat{\epsilon}_d$ を目的関数として勾配に基づく数値最適化を行い、プライバシー違反を大きくする方向に入力と出力集合を探索します。

以上の流れを図にしたものが論文中の Fig.5 です。DP-Finderでは複数回（$N$回）の反復を行い、毎回ランダムに初期候補$(x,x',\Phi)$を選んで上記(1)(2)の手順で局所的な探索を行います。各イテレーションで得られた違反度がそれまでの最高値を更新した場合はその反例を記録し、最終的に最大違反度を与えた反例を出力します。

最後に、得られた反例$(x,x',\Phi)$に対しては検証ステップが行われます。推定プロセスで近似や乱数固定を用いているため、その違反度評価が厳密でない可能性があります。そこでDP-Finderは最終候補について正確な違反度 $\epsilon(x,x',\Phi)$ を改めて計算します。この際にはPSIによる記号的解析を具体的な入力に対して実行し（記号的に一般式を解くのではなく、見つけた特定の$x,x'$に対する確率を計算する）ことで $\Pr[F(x)\in\Phi]$ などを正確に求めます。PSIがタイムアウトした場合には、サンプル数を非常に増やしてHoeffding不等式に基づく厳密な信頼区間を付けた推定値を算出します。著者らの評価では用いたベンチマークでPSIがタイムアウトすることはなく、この検証工程は常に成功しています。

以上がDP-Finderの全体像です。以下では各ステップについて数学的な詳細を掘り下げます。

プライバシー違反度推定関数 $\hat{\epsilon}(x,x',\Phi)$ の構築

推定関数 $\hat{\epsilon}$ の定義: まず、ある固定した候補 $(x,x',\Phi)$ に対し、真の違反度 $\epsilon(x,x',\Phi) = \log \frac{\Pr[F(x)\in\Phi]}{\Pr[F(x')\in\Phi]}$を推定する方法を定めます。乱数を使うアルゴリズム $F$ の確率を評価するため、DP-Finderはモンテカルロサンプリングによって $\Pr[F(x)\in\Phi]$ を推定します。具体的には、確率変数 $S := [F(x)\in\Phi]$ を導入します（$[P]$はIverson記号で、命題$P$が真なら1、偽なら0を返す）。この$S$はベルヌーイ分布に従い、その期待値はまさに $\Pr[F(x)\in\Phi]$ に等しくなります。ゆえに独立な試行からなるサンプル $S_1,\dots,S_n$ を得れば、その標本平均 $\frac{1}{n}\sum_{i=1}^n S_i$ が確率$\Pr[F(x)\in\Phi]$の推定量となります。同様に $x'$ 側の確率もサンプリングで推定します。

DP-Finderはこのサンプリングを効率良く行うために、チェック関数と呼ばれる補助プログラムを構成します。もとの確率的アルゴリズム $F$ に対し、$F(x)$ の出力が$\Phi$に属するかを判定するランダム化プログラム $ \mathit{check}{F,\Phi}(x) := [,F(x)\in \Phi,]$ を考えます。これは $F$ を実行した後に結果が$\Phi$に含まれるかを返すもので、出力は0/1の確率変数になります。DP-Finderでは、この $\mathit{check}{F,\Phi}(x)$ 内の確率的選択を固定して決定的なプログラム $\mathit{check}^i_{F,\Phi}(x)$ を複数作り出します。すなわち、$F$ 内で用いる乱数（例えばLaplace分布やコイン投げなど）をあらかじめ $i$ 番目のシードに対応する値にサンプリングしておき、その乱数を定数として埋め込んだ$\mathit{check}^i_{F,\Phi}(x)$を構築します。こうして得られる $\mathit{check}^i_{F,\Phi}(x)$ は純粋に$x$の関数となり、返り値は $F(x)$ が特定の乱数シナリオの下で$\Phi$に属するか否かを表す0/1値になります。

この方法で $i=1,2,\dots,n$ について決定的チェックプログラムの集合 ${\mathit{check}^i_{F,\Phi}}_{i=1}^n$ を用意すれば、推定確率を以下のように計算できます。

Pr[F(x)∈Φ]=n1i=1∑ncheckF,Φi	​(x),D
Pr[F(x′)∈Φ]=n1i=1∑ncheckF,Φi​(x′).

ここで $\Pr_D$ は「サンプル上の経験的確率」を意味します。実際には左辺は大数の法則により $n\to\infty$ で真の確率に収束します。このように各側の確率を推定した上で、違反度の推定値を対数比

ϵ^(x,x′,Φ)=logPrD​[F(x′)∈Φ]PrD​[F(x)∈Φ]​=logn1​∑i=1n​checkF,Φi​(x′)n1​∑i=1n​checkF,Φi​(x)​

として定義します。この量$\hat{\epsilon}(x,x',\Phi)$が有限のサンプル上での推定違反度です。なお文献では簡潔に$S_i := \mathit{check}^i_{F,\Phi}(x)$、$S'i := \mathit{check}^i{F,\Phi}(x')$と置き、この式(6)を表現しています。

相関サンプリング: DP-Finderが特徴的なのは、$x$と$x'$で対応するサンプルに同一の乱数を用いている点です。すなわち上式の $\mathit{check}^i_{F,\Phi}(x)$ と $\mathit{check}^i_{F,\Phi}(x')$ は、乱数シードやノイズシーケンスの選び方が同一になるよう構成されています。このおかげで、$x$と$x'$の出力差異が同じ乱数の下で比較されることになり、2つの確率推定値の間に強い正の相関が生まれます。直感的には、「$x$と$x'$が似た入力ならば、同じ乱数を使えば似た挙動を示す」ため、それらの出力が共に$\Phi$に属するか否かが同期しやすくなり、確率比の分散が縮まる効果があります。この手法により必要なサンプル数$n$を大幅に削減できることが本論文の重要な洞察です。ただし、異なる $i \neq j$ の間では独立に乱数を選ぶ（サンプルごとは独立）ため、$i$内でのみ$x$側と$x'$側が強く相関する仕組みです。

サンプリングによる確率推定と信頼区間の算出

上記の方法で計算される $\hat{\epsilon}(x,x',\Phi)$ はあくまで有限サンプルに基づく推定です。したがって統計的誤差があり、サンプル数$n$が小さいと推定値が真値から乖離している可能性があります。DP-Finderでは探索プロセスにおいて、この推定誤差が十分小さくなるようサンプル数を増減させる戦略をとっています。具体的には、初めは比較的少ないサンプルで$\hat{\epsilon}$を計算し、途中途中で信頼区間 (confidence interval) を推定します。信頼区間の幅（半長）$\Delta \epsilon$が所定の閾値より大きいうちは更に追加サンプリングを行い、幅が十分小さくなった時点でその$n$をもって先に進みます。たとえば論文中では絶対誤差$\Delta\epsilon = 2\times 10^{-3}$程度（約0.002）になることを目標にしています。

Hoeffdingの不等式による厳密な信頼区間

信頼区間推定のアプローチの一つ目は、Hoeffdingの不等式に基づくものです。Hoeffdingの不等式は確率変数が特定の範囲に収まる場合に汎用的に適用できる濃度不等式であり、ベルヌーイ試行の平均にも適用できます。$S_1,\dots,S_n$ を独立なベルヌーイサンプル（平均$p=\Pr[F(x)\in\Phi]$）とすると、Hoeffdingの不等式より

Pr[​n1​∑i=1n​Si​−p​>δ]≤2exp(−2nδ2)

が成立します。これを逆に用いれば、例えば確率 $1-\alpha$ で真の確率$p$が推定値$\frac{1}{n}\sum S_i$の±$\Delta$の範囲に入るような誤差幅$\Delta$は

2exp(−2nΔ2)=α

を満たす解として $\Delta = \sqrt{\frac{\ln(2/\alpha)}{2n}}$ と与えられます。DP-Finderでは各確率に対しこの信頼区間を計算し、ユニオンブード（合成事象の確率評価）によって両方の確率推定が同時に真の範囲を外れないための保証を付与します。具体的には、各側それぞれに失敗確率$\alpha/2$を割り当てれば、両者同時成功する確率は少なくとも$(1-\alpha/2)^2 \approx 1-\alpha$となります（厳密には和集合の確率で上界$\alpha/2+\alpha/2=\alpha$）。この場合、推定違反度$\hat{\epsilon}$に対して真の違反度$\epsilon$がどの程度ズレうるかを以下のように評価できます。

下限: 最悪の場合、$x$側の真の確率が推定より$\Delta$小さく、$x'$側が推定より$\Delta$大きいとき、$\epsilon$は $\log\frac{p-\Delta}{q+\Delta}$ まで小さくなり得ます。

上限: 逆に $x$側が$\Delta$大きく、$x'$側が$\Delta$小さい場合、$\epsilon$は $\log\frac{p+\Delta}{q-\Delta}$ まで大きくなり得ます。

したがって $\epsilon$ は区間

[log(q+Δ/p−Δ​),log(q−Δ/p+Δ)​]

に（高い確率で）収まることがわかります。例えば論文中のあるケースでは $p\approx 3.24%, q\approx 3.04%$、サンプル数$n=10^7$に対し$\Delta\approx0.06%$（失敗確率$0.1%$相当）となり、上式から $\epsilon$ の信頼区間は約 $[0.024,;0.103]$ と算出されています。この幅$\approx0.079$が求める誤差$\Delta\epsilon$に当たります。Hoeffdingに基づくこの方法は厳密な保証を持ちますが、ベルヌーイ分布の分散やサンプル間相関といった情報を一切利用していないため、区間幅がどうしても保守的（大きめ）になってしまうという欠点があります。実際、この手法で目標の精度を得るには非常に多くのサンプルを要する場合があるため、著者らは以降で統計的な仮定を導入したヒューリスティックにより改良を試みています。

中心極限定理 (CLT) に基づくヒューリスティックな信頼区間

サンプル数が大きい場合には、中心極限定理 (Central Limit Theorem) を用いて標本平均の分布を正規分布で近似することができます。ベルヌーイ試行の場合、$S_i$の分散は$p(1-p)$ですから、

$ \frac{1}{n}\sum_{i=1}^n S_i ;\approx; \mathcal{N}!\Big(p,;\frac{p(1-p)}{n}\Big)$,

$ \frac{1}{n}\sum_{i=1}^n S'_i ;\approx; \mathcal{N}!\Big(q,;\frac{q(1-q)}{n}\Big)$,

という2つの正規近似が得られます（$n$が大きいほど厳密に近づく）。この近似を仮定すれば、各確率推定値に対し「誤差が標準正規分布で$\alpha/2$両側点を与える範囲内に入る」ような幅$\Delta'$を計算できます。換言すれば、例えば$1-\alpha/2=99.95%$区間に相当する誤差幅は $\Delta' = z_{1-\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ で与えられます。実際の実装では真の$p,q$は不明なため標本値である $\hat{p},\hat{q}$ を用いて分散を推定します（経験的分散の定義は論文付録B参照）。こうして各側に対し経験的信頼区間 $[\hat{p}\pm\Delta'_p]$, $[\hat{q}\pm\Delta'_q]$ を構成し、Hoeffdingの場合と同様にユニオンバウンドで結合します。

中心極限定理に基づくこの方法はあくまでヒューリスティックであり、有限サンプルでは正規分布からのずれが生じうる点に注意が必要です。著者らも「$n=1$でも正規と仮定してしまうなど厳密には誤りだが、$n=10^3$程度あれば分布形状はかなり正規に近づき誤差は無視できる」と述べています。この仮定のもとで得られる信頼区間はHoeffdingより狭くなる傾向があり、したがって目標の精度を達成するための必要サンプル数も削減できます。上述の$p\approx3.24%, q\approx3.04%$の例では、CLTに基づく計算により$\Delta'\approx0.02%$が得られ、それぞれ $[3.24%\pm0.02%]$, $[3.04%\pm0.019%]$ の区間となりました。この場合、$\epsilon$の区間は $\log\frac{3.24%-0.02%}{3.04%+0.019%} \approx 0.051$ から $\log\frac{3.24%+0.02%}{3.04%-0.019%}\approx0.076$ となり、幅は $0.025$ 程度に縮まりました。これは同じ信頼度（約99.9%）でHoeffding法の幅0.079と比べ約1/3になっています。

多次元CLT (M-CLT) とノイズ相関の活用

さらにDP-Finderは相関サンプリングによる2変量同時分布の観点から信頼区間を改良しています。先述の通り、各サンプル$i$に対して $(S_i, S'_i)$ は独立ではなくある程度相関しています。特にDP-Finderの工夫によりこの相関は非常に強く、場合によっては $\rho \approx 0.999$ にも達します。相関が高いということは「$x$と$x'$の結果がほぼ同時に1か0になる」ことを意味し、違反度の比 $\frac{\hat{p}}{\hat{q}}$ のばらつきが極めて小さくなることを示唆します。その結果、必要サンプル数も大幅に削減可能です。Fig.6は推定確率の値を固定したときに目標誤差を達成するのに必要な$n$の比較を示していますが、どの確率値においてもM-CLTに基づく手法が他手法より少ないサンプルで済むことが示されています。

技術的には、多次元の中心極限定理を用いて $(\bar{S}, \bar{S}') = \Big(\frac{1}{n}\sum S_i,; \frac{1}{n}\sum S'_i\Big)$ の分布を2次元正規分布で近似するところから始まります。具体的に、$S=(S_i,S'_i)$ を2次元のサンプル（各サンプルはペア値）とみなすと、その期待値は $(p,q)$、共分散行列は $\Sigma = \mathrm{Cov}(S_i,S'_i)$ によって決まります。これを平均 $(p,q)$、分散共分散 $\frac{1}{n}\Sigma$ の2次元正規分布で近似すると、$(\bar{S},\bar{S}') \approx \mathcal{N}_2!\Big((p,q),;\frac{1}{n}\Sigma\Big)$ と表せます。このとき我々が関心を持つのは比率 $R = \frac{\bar{S}}{\bar{S}'}$、特にその対数 $\log R$ の分布です。2変量正規に従う2つの変数の比率分布に関しては、統計学においてHinkleyの定理が知られており、その累積分布関数 (CDF) を解析的に記述できます。DP-Finderではこの結果を利用して $\log(\Pr[F(x)\in\Phi]/\Pr[F(x')\in\Phi])$、すなわち $\epsilon(x,x',\Phi)$ の分布を近似し、そこから所望の信頼区間を読み取るというアプローチを取っています。

具体的には、まず観測された標本平均 $(\hat{p},\hat{q})$ をもとに真の$(p,q)$への事後尤度（信念分布）を2次元正規で仮定します。Fig.7（論文）ではこの様子が図示されており、$\mathbb{R}^2$空間で$(p,q)$に対するガウス分布の輪郭が描かれています。そこから写像 $(p,q)\mapsto \log(p/q)$ を施すことで$\epsilon$の推定分布が得られます（図中では山なりの分布として描画）。最後に、その分布に対して「確率$1-\alpha$で真の$\epsilon$が$\hat{\epsilon}$の±$\Delta$以内に入る」ような最小の幅$\Delta$を求めます。これは分布の両側積分が$\alpha/2$になる上下限点を探す問題ですが、解析的に解くのは難しいためDP-Finderでは2分探索によって適切な$\Delta$を数値的に見つけています。こうして得た$\Delta$を用い、$\epsilon$の信頼区間 $[\hat{\epsilon}-\Delta,; \hat{\epsilon}+\Delta]$ を構成します。

CLTに基づく手法と同じ例で比較すると、M-CLTを用いるとさらに狭い区間が得られるはずです。論文中では上記$p\approx3.24%, q\approx3.04%$で相関$\rho=0.97$の場合について計算が行われています。このとき $\hat{\epsilon}\approx\log(3.24%/3.04%)\approx0.064$（6.4%）で、経験的な分散はそれぞれ$3.13%, 2.95%$と見積もられ、相関0.97が観測されました。この情報から2次元正規の尤度を設定し、ヒューリスティックに$\epsilon$の分布を導出した結果、例えば信頼度99.9%では $\epsilon$ がだいたい $0.064 \pm 0.01$ 程度の範囲に収まることが示唆されています（※正確な値は文献に明示されていませんが、CLT単独の場合0.025だった区間幅がM-CLTでさらに縮むのは確実です）。このようにM-CLTにより非常に鋭い誤差評価が可能となり、逆に言えば必要なサンプル数が劇的に減少します。著者らはFig.6でサンプル数の比較を提示し、どのような確率値においてもM-CLT手法が他の方法を上回る効率を示すことを確認しています。

以上まとめると、DP-Finderではまず経験的に推定違反度$\hat{\epsilon}$を計算し、さらにM-CLTに基づくヒューリスティックで「その推定がどれだけ信頼できるか」を評価しています。実装上はまず少ないサンプルで試し、だんだんサンプル数$n$を増やしながら上記の信頼区間幅$\Delta\epsilon$を推定し、$\Delta\epsilon$が目標以下になるまで続けるという手順を踏んでいます。こうすることで無駄に過剰なサンプルを取らずに済み、かつ十分な精度が担保された状態で次の探索フェーズへ進めます。

非微分可能な関数の微分可能関数への変換

推定違反度 $\hat{\epsilon}(x,x',\Phi)$ はサンプルごとの指示関数$\mathit{check}^i_{F,\Phi}(x)$を含んでいます。これは本質的に0/1の離散的な関数であり、入力$x$に対して不連続に値が飛びうるため微分不可能です。例えば$\mathit{check}$内では確率的アルゴリズム$F$の振る舞いが定数化されているとはいえ、$F$の内容に条件分岐や比較演算が含まれる場合、入力が閾値を跨ぐだけで出力が0から1にパタッと変化する箇所が存在します。これでは勾配$\nabla_{x}\hat{\epsilon}$を計算できないため、DP-Finderではプログラム変換によりこれらの非連続性を滑らかな関数で近似します。

対象となる$\mathit{check}^i_{F,\Phi}(x)$は決定的プログラムですから、その中の命令列を解析して各ステートメントを置換していきます。著者らは特にブール値を計算する演算（論理演算や比較演算）およびif文が非微分性の原因である点に着目し、それらを実数値の滑らかな関数に対応付けるルールを定義しました。Fig.8（論文）にそのルール一覧が示されています。主要なものを挙げると:

否定 ¬B ： -> $1 - B$ に変換（まず論理値を0/1実数に埋め込み、以降の変換ルールを再帰的に適用）。

論理積 B1 && B2 ： -> $B1 \cdot B2$ に変換。両方真なら$1\cdot1=1$、どちらか偽なら0を含む積で0となり、論理積の意味を連続的に実数で表現します。

論理和 B1 || B2 ： -> $B1 + B2 - B1\cdot B2$ に変換。これも$B1,B2$が0/1ならブールのORと一致し、中間値でも0～1の範囲の連続値となります（これは確率論で和事象の指示関数を足し算で表す式と同じ形です）。

等値比較 E1 == E2 ： -> $\exp(-c,(E1 - E2)^2)$ に変換。2つの式が等しければ差分$0$で$\exp(0)=1$、異なれば差の2乗に比例して急速に0に近づく関数です。係数$c$は大きな定数で、$c\to\infty$とすれば元のブール値と同じ意味になります。実装では十分大きな$c$（例えば50）を採用することで「ほぼ0/1」に振る舞わせます。

不等比較 E1 ≤ E2 ： -> シグモイド関数 $\frac{1}{,1 + \exp(-c,(E2 - E1)),}$ に変換。$E1 \ll E2$ なら分子優勢で値$1$に近く、$E1 \gg E2$ なら$0$に近い値となり、2項の大小を滑らかに判定します。シグモイドの急峻さもパラメータ$c$で調節します。

if分岐 if (B) { x = E1 } else { x = E2 } ： -> $x := B\cdot E1 + (1-B)\cdot E2$ に変換。ここで$B$はブール条件を$0\sim1$の実数に緩和したもの（上記変換後の値）です。この式は$B\approx1$なら$x\approx E1$、$B\approx0$なら$x\approx E2$となり、条件分岐の効果を実数計算で表現しています。

同様にelseなしの単独ifも $x := B\cdot E1 + (1-B)\cdot x$ のように書き換えます。また論理否定は上述の通り $1-B$ への置換です。以上に示したように、ブール値はすべて連続値（実数の0～1）にマッピングされ、条件分岐は対応する式の重み付き和に解消されます。Fig.8のルールを適用すれば、許された範囲の命令を持つどんなプログラムでも機械的に変換できます。

このようにして得られた差分可能なチェックプログラム $\mathit{dcheck}^i_{F,\Phi}(x)$ は、入力の連続変化に対し滑らかに出力も変動します。そこでDP-Finderでは、本来の $\hat{\epsilon}(x,x',\Phi)$ における$\mathit{check}$を$\mathit{dcheck}$に置き換えた近似目的関数 $\hat{\epsilon}_d(x,x',\Phi)$ を定義します。式で表せば、

ϵ^d​(x,x′,Φ)=logn1​∑i=1n​dcheckF,Φi​(x′)n1​∑i=1n​dcheckF,Φi​(x)​,

となります（ただし実装上は分子分母それぞれに$n$倍を吸収させています）。この $\hat{\epsilon}_d$ は構成上すべての内部計算が滑らかな関数になっているため、勾配降下法などの数値最適化で扱うことが可能な目的関数となります。

重要なのは、変換後の $\hat{\epsilon}_d$ はあくまで近似であって元の $\hat{\epsilon}$ と完全に一致するわけではないことです。$c$パラメータを有限にとっている以上、例えば $E1 == E2$ の判定もわずかに1未満の値を取ったりしますし、連続化ゆえにブールの意味論が崩れているケースもあります。しかし著者らの評価によれば、変換後に最大化された$\hat{\epsilon}_d$から対応する$\hat{\epsilon}$を計算してみると、両者の値はかなり近くなる傾向があると報告されています。これは滑らかな目的関数で探索することによって、元の非滑らかな空間でも高い値を取る領域をうまく発見できていることを示唆します。そのため、多少のズレは許容してもこの変換を用いるメリット（勾配法による系統的探索が可能になること）は大きいと考えられます。

ただし変換の適用には前提があります。サポートされるプログラム構造は有限の条件分岐とブール演算に限られており、無限ループや入力量に依存する回数のループなどはサポート外です（ただし静的に展開可能な有限ループは展開して対応可能）。また、仮にサポート外のプログラムであってもDP-Finder自体は動作不能になるわけではなく、その場合は分岐変換を行わずにランダム探索（後述）で違反例を探すモードにフォールバックする設計になっています。しかし筆者らの実験では、この場合はやはり見つかる違反度が低めになってしまうことが示されています。

数値最適化による探索手法の統合

上述のようにして得られた微分可能な目的関数 $\hat{\epsilon}_d(x,x',\Phi)$ を最大化するため、DP-Finderは数値最適化アルゴリズムを用いて探索を行います。論文では制約付きの勾配法として逐次二次計画法 (Sequential Least Squares Programming, SLSQP) を利用したと述べられています。SLSQPは制約条件もスムーズに扱えるため、入力ペア$(x,x')$が隣接関係$(x,x')\in\mathit{Neigh}$にあるという条件もそのまま組み込んで最適化できます。DP-FinderではこのSLSQP実装（TensorFlow内の版を利用）に対し、初期点としてランダムに選んだ $(x,x')$ と $\Phi$ を与え、$\hat{\epsilon}_d$を最大化する解を見つけます。すなわち以下の代理最適化問題を解く形になります。

max​ϵ^d​(x,x′,Φ)s.t.(x,x′)∈Neigh.

この問題(12)は連続最適化ですから、理論的には局所解に陥る可能性があります。$\hat{\epsilon}_d$自体も必ずしも凸ではなく、例えば $y=x\cdot x\cdot x$ のような計算がプログラム中にあれば目的関数は多峰的になり得ると指摘されています。しかし機械学習における損失最適化などと同様、勾配法で全局的によい解を見つけられることが経験的には多いため、本手法でも有効であろうという立場です。実際DP-Finderは単一の初期点に頼らず、複数回（$N$回）ランダムに初期化して最適化を繰り返すことで局所解の問題を緩和しています。

なお、探索開始前にエッジケースの除外が行われます。それは分母（$x'$側確率）の推定が0になってしまった場合です。$\hat{\epsilon}_d$の定義上、分母が0だと対数が発散し値が定まりません。この状況は、例えばサンプル上で一度も $F(x')\in\Phi$ が起こらなかった場合に起こります。DPの定義から言えば、もし$\Pr[F(x')\in\Phi]=0$かつ$\Pr[F(x)\in\Phi]>0$であればそのアルゴリズムは無限大のプライバシー違反（つまり全くプライバシー保護がない状態、$\epsilon=\infty$すら違反しうる）であることが分かります。この場合は最適化を走らせるまでもなく、その$(x,x',\Phi)$が決定的にプライバシーを破っている（片方の入力でしか生じ得ない出力がある）ことになるので、DP-Finderはただちにその組を解として返します。逆に、もし両者の推定確率がどちらも0なら、そもそもその$\Phi$はどちらの入力でも発生しない出力なので何の情報も引き出せません。この場合はその候補をスキップして新たな候補に切り替えます。

SLSQPによる探索の結果、ある局所的な最適解 $(x^,x'^,\Phi^)$ が得られたとします。その時点での $\hat{\epsilon}_d(x^,x'^,\Phi^)$ は高い値を示すでしょうが、前述のようにこれは元の$\hat{\epsilon}$とはズレがある可能性があります。また、$dcheck$プログラム内に固定した乱数（シード）の偶然によっては、そこで過剰適合（オーバーフィット）してしまい、そのシード以外では再現しない巧妙な違反を見つけてしまうリスクもあります。著者らはこれらを不正確さの要因 (sources of imprecision) と呼び、(i) $\hat{\epsilon}_d$の最大点が必ずしも$\epsilon$の最大点と一致しないこと、(ii) 特定の乱数固定に過剰適合して本質的でない違反例を返す可能性、の2点を挙げています。これらに対処するため、DP-Finderは最終確認処理を施します。すなわち前節で述べたPSI等による正確な違反度計算を行い、本当にその反例が高い違反度を持つかを検証するのです。仮にPSIがタイムアウトするようなら、サンプル数を増やした厳密推定で代替します。こうして得られた確からしい違反度付きの反例$(x^,x'^,\Phi^*)$がユーザに報告されます。

以上がDP-Finderの探索パイプラインです。補足として、探索そのものではPSI等の記号解析は使われていない点に注意が必要です。PSIは計算コストが高く汎用性も限られるため、最終確認のみにとどめ、探索自体はすべて推定と勾配法で行うというのがDP-Finderの設計思想です。実際、PSIを用いて最適化まで含め直接解こうとすると、簡単な場合でも歯が立たなかったことは既に述べました。DP-Finderはこの制約をうまく回避し、サンプリング＋最適化という実用的な道筋を示した点が新規性となっています。

シンボリック確率計算 (PSIの使用) とその限界

PSI（Probabilistic Symbolic Inference）は確率的プログラムの分布や期待値を記号的に計算する手法で、DP-Finderの著者らによって開発されたツールです。DP-Finderでは当初このPSIで確率計算を行い、Mathematicaで最適化するという完全解析的アプローチを試みましたが、前述の通り実用には至りませんでした。PSIは小規模な問題には成功しましたが、配列長4のアルゴリズムで6時間計算しても完了しないなど、入力の規模が少し大きくなると途端に厳しくなります。DP-Finderはその反省から、PSIを探索過程には組み込まず検証フェーズのみで使うようにしています。このとき具体的な入力に対する確率を計算するだけで済むため、PSIの負荷は大きくなく、著者らの実験では全ケースでPSIが時間内に計算を終えています。

PSIの限界としては、上記のスケーラビリティ問題に加え、扱えるプログラムの表現力にも制約がある点が挙げられます。DP-FinderではPSI用に各アルゴリズムの$\mathit{check}_{F,\Phi}$を実装していますが、PSIがサポートしない構文（例えば再帰的なデータ構造や大きなループ）は扱えません。そのためPSI導入には問題設定をある程度単純化する必要があります。DP-Finderのケースでは幸い、テスト対象としたアルゴリズムはいずれもPSIで解析可能な範囲に収まっていたため、検証に成功しています。しかしより複雑なアルゴリズムの場合、PSI検証がタイムアウトしたり、実装を簡略化しないと解析できなかったりする可能性があります。著者らも「PSIがタイムアウトした場合にはSec.4.5（M-CLTの手法）とSec.4.3（Hoeffdingの手法）を組み合わせて最終確認することも可能」と述べています。要は、DP-Finder自体はPSIに強く依存しない設計で、PSIなしでも厳密な信頼区間付き推定で代替できるよう工夫されています。総じて、PSIは最終的な違反度の正確な確認という限定的用途に使われ、探索効率を損なわない範囲で利用されていると言えます。

実験による評価と結果指標

論文ではDP-Finderをいくつかの既知アルゴリズムに適用し、その有効性を評価しています。対象とされたのは主に差分プライバシーアルゴリズムの代表例やその変種で、以下の9つです。

AT (Above Threshold) – ある閾値$T$を超えるか否かを判定する基本アルゴリズム（Lyuらの論文[26]からの簡略版）。入力は数値配列、出力は各要素が閾値超過したかを示すブーリアン配列です。プライバシー保護のため閾値$T$やクエリ結果にノイズを加えています。

AT1～AT4 – ATの亜種。論文中でノイズスケールや手順を少しずつ変えた4つの変種として示されています（例えばAT1は閾値ノイズのスケールを変更、AT4は閾値と入力ノイズ双方のスケール変更など）。

AT5 – ノイズを加えない変種。これは明らかに非プライベート（$\epsilon=\infty$）なケースです。

ExpMech (Exponential Mechanism) – 差分プライバシーの指数メカニズム。高スコアを持つ要素を確率的に選択する機構で、所定の$\epsilon$を達成するよう設計されています。

NoisyMax – 複数値の中から最大値インデックスを選ぶ処理にノイズを足したもの。

Sum – データベース集計の合計を返す処理にノイズを加えたもの。

これらについて、それぞれ既存研究から知られている**公称の$\epsilon$上限値（理論的保証値）**が設定されています。例えばATは0.1-DPとなるようノイズ設定されており、AT4は0.175-DP、AT5は$\infty$-DP（非公開）などです。

DP-Finderは各アルゴリズムに対し50回の反例探索を行い、毎回見つけた反例の真の違反度（PSI等で確認した$\epsilon$値）を計測しました。また、ベースライン比較としてランダムサーチ（出力集合$\Phi$と隣接入力$(x,x')$をランダムサンプリングで選ぶだけ）でも50個の反例を集め、それらの違反度も計算しました。Fig.12（論文）にその結果のボックスプロットが示されています。総合すると、DP-Finderはランダム探索よりも遥かに高い違反度の反例を発見できることが確認されています。中央値で比較すると、違反度の改善倍率はアルゴリズムによって2倍（AT4の場合）から33倍（Sumの場合）にも達しました。特に「Sum（集計）」ではランダムにはほとんど見つけられないような強い漏洩ケースをDP-Finderが捉えていることになります。

さらに、見つかった違反度と理論上の上限値との比較も興味深い結果を示しました。ExpMechに関しては、全ての試行で発見下限値（違反度）が上限値に極めて近く、一致していると見做せるレベルでした。これはExpMechの既知のプライバシー保証がtight（実際に達成されている）であることを示唆します。一方、AT系列の他のアルゴリズムではDP-Finderが見つけた下限値と既知上限値の間にギャップがあるものもありました。例えばAT4の理論上限0.175に対しDP-Finder下限はそれより小さい値でした。このギャップが意味するのは2通り考えられます。(a) 上限値が実は緩すぎて改善の余地がある（真のプライバシー保証はもっと小さい$\epsilon$でよい可能性）、(b) DP-Finderがまだ最悪ケースを見つけきれていない（局所最適に留まった）可能性です。著者らは現状どちらとも判断できないとしつつも、DP-Finderで反例が見つからなかった場合は前者（証明上限を改善できる）かもしれず、逆に見つかった場合はその上限がtightであることの証左になると述べています。いずれにせよ、DP-Finderはこのように既存理論の検証手段にもなり得る点が大きな意義です。

他の評価指標として、処理時間とサンプル数があります。Fig.13（論文）では各アルゴリズムごとにDP-Finderの1イテレーション当たりの時間内訳が示されています。平均すると、最適化部分（SLSQP）の計算に全体の大半（おおむね7～8割）の時間を費やしており、サンプリングと最終確認(PSI)のコストはそれに比べ小さいことが分かります。それでも1回の探索イテレーション（サンプリングしつつ最適化して反例1つ得るまで）の処理は全アルゴリズムで平均5分以内に収まっており、実用上充分な効率といえます。最適化問題自体が難しい割には健闘している、と著者らも述べています。一方、アルゴリズムや初期条件によって探索に必要なサンプル数$n$は大きく変動しました。Fig.14（論文）によると、同じアルゴリズム内でも反例によって要求サンプル数が異なり、例えばAT系では$10^4$～$10^7$程度の幅でばらついています。Sumアルゴリズムでは最大で$10^7$以上のサンプルを取るケースもありました。これは、推定確率の値が極端に小さい場合などに高精度を得るため追加のサンプルが必要になるためです。DP-Finderはこのように適応的にサンプル数を増減させているため、効率よく精度管理ができています。一律に大サンプルを取るのではなく、必要な場合にだけ増やすことで無駄を省いている点も本手法の実装上の工夫といえます。

総じて、実験結果はDP-Finderの有効性と効率性を示すものでした。高い違反度の反例を自動で見つけ出せること、既知のプライバシー保証の妥当性検証に使えること、そして手作業では困難な大きな探索空間（連続値の組合せ）から漏洩パターンを発見できることが確認されました。著者らはDP-Finderを「新たなアルゴリズムのプライバシー評価ツール」や「既存理論の厳密性テスト」に活用できるとし、さらには攻撃者がこのような手法で情報漏洩パターンを探す可能性にも言及しています。今後の展望としては、入力依存のノイズ（現在は独立と仮定）への対応拡張や、より複雑な確率的プログラムへの適用などが考えられます。DP-Finderは差分プライバシーの研究と実践双方にとって貴重なツールと言えるでしょう。