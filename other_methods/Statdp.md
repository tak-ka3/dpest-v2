『Detecting Violations of Differential Privacy』の手法解説

本稿では、Dingらによる論文「Detecting Violations of Differential Privacy」の提案手法について、差分プライバシーの理論的前提ではなく実装的・統計的側面に焦点を当て、各要素技術を可能な限り深く解説します。提案手法は、アルゴリズムの実装をセミブラックボックス方式で多数回実行し、その出力分布の違いに統計的検定を適用することで、差分プライバシー違反（プライバシー保証の不成立）を検出し、人間が理解しやすい反例（カウンターエグザンプル）を自動生成するものです。以下、論文で提示された主要アルゴリズム（Algorithm 1～4）および評価実験結果について、順に詳述します。

1. Counterexample Generator の全体構成（セミブラックボックス方式、アルゴリズム1）

提案手法の全体像はAlgorithm 1: CounterExampleDetectionにまとめられています。このアルゴリズムは、入力としてターゲットのメカニズム実装 M（差分プライバシーアルゴリズム）とその主張するプライバシーパラメータϵを受け取り、以下の手順で進みます：

入力候補の生成（InputGenerator）: 最初に、Mに与える隣接データベースの候補ペア $(D_1, D_2)$ と、Mが必要とするその他のパラメータ args の組を複数生成します。この集合を InputList と呼びます。各 $(D_1, D_2)$ は差分プライバシーの定義における隣接関係（1件だけデータが異なる or 1カウントだけ異なるなど）を満たすペアで、しかも短く単純になるよう工夫されています。反例ペアは開発者が理解しやすいよう、できるだけ小規模なデータで提示されることが望ましいためです。またMの実行が後続で多数回行われるため、データサイズは小さく抑えられ効率も良くなっています。

イベント選択（EventSelector）: 次に、InputList内の各候補についてM(D_1, args)とM(D_2, args)をそれぞれ**$n$回反復実行し、出力の統計を収集します。出力の型に応じて、後述するような候補イベント集合** $S$（$E$の候補集合）を構築し、各イベント $E \in S$ について「出力がイベント$E$に属する回数」をそれぞれカウントします（$c_1 = |{i | O1[i] \in E}|$, $c_2 = |{i | O2[i] \in E}|$）。そして統計的仮説検定モジュール（Algorithm 2）を用いて、そのイベント$E$が差分プライバシー違反を示唆する尤もらしさ（p値）を算出します（$D_1$側・$D_2$側のいずれの不等式違反の場合も評価）。各候補ごとに最も小さいp値（最も強い違反の兆候）を記録し、その際の $(D_1, D_2, args, E)$ を保存します。最終的に、全候補中で**最もp値の小さい（有意な）**組合せ $(D_1, D_2, args, E)$ を選び出し、これが後続の厳密検定に回されます。

注: EventSelector内部では、多数の候補に対して仮説検定を探索的に実行しているため、最終的に選ばれた組合せについては新たにサンプルを取り直して検定をやり直す必要があります（後述のHypothesisTestを再度実行）。これは、多重比較による偶然の検出（いわゆる「p値ハッキング」）を避け、統計的な健全性を保つためです。EventSelectorでは候補イベントがあまりにも稀な場合（例えばサンプル中ほとんど出現しない$E$）はノイズが大きく信頼できないためスコア計算をスキップする工夫もされています（具体的には $c_E = c_1+c_2$ が $0.001 \cdot n \cdot e^{ϵ}$ 未満の場合はその$E$を無視する）。

仮説検定（HypothesisTest）: 最後に、選択された反例候補 $(D_1, D_2, args)$ とイベント $E$について、改めてM(D_1)とM(D_2)を多数回実行して厳密な統計的検定を行います。具体的には、再度 $n$回ずつ実行して出力を集め、$c_1, c_2$（イベント$E$が生じた回数）を数え、それに基づいて差分プライバシー違反の有意性を示す2つのp値（片側検定のp値）を算出します。片方のp値 $p_{\top}$ は「$P(M(D_1)\in E) > e^{ϵ} P(M(D_2)\in E)$」すなわち$D_1$側の確率が大きすぎる場合の有意性、もう一方 $p_{\bot}$ は「$P(M(D_2)\in E) > e^{ϵ} P(M(D_1)\in E)$」すなわち$D_2$側が大きすぎる場合の有意性を示します。両者のうち小さい方のp値が、当該アルゴリズムがϵ-差分プライバシーを満たしていないことを示す統計的な証拠の強さとなります。

以上の流れにより、本手法は対象アルゴリズムMが主張するプライバシーレベルϵについて、その真偽を検定し、もし不正確であれば具体的な反例（隣接入力$D_1, D_2$と出力事象$E$）を返します。このアプローチは、言語や実装形式に依存しないブラックボックス検査を志向していますが、必要に応じてプログラム解析（シンボリック実行）も組み合わせて効率を高めているため「セミブラックボックス」と称されています。すなわち、基本的にはコードをそのまま実行して得られる入出力の統計に頼りますが、探索すべき入力候補やパラメータを自動生成する際には、対象プログラムのソースコードを部分的に解析して分岐構造を利用する部分も含まれています。この入力生成部やイベント選択部については後述します。

2. Hypothesis Testing（アルゴリズム2、および p値計算の方法）

差分プライバシー違反を検出するための統計的仮説検定では、隣接データベース入力$D_1, D_2$に対するメカニズムMの挙動差を検証します。差分プライバシーの定義上、$M$がϵ-差分プライバシーを満たすなら任意の事象$E$について確率比 $P(M(D_1)\in E) / P(M(D_2)\in E)$ は $\le e^{ϵ}$ に収まるはずです。従って、違反を示すには「ある事象$E$について $P(M(D_1)\in E) > e^{ϵ} \cdot P(M(D_2)\in E)$ となっている」ことを統計的に示せればよいことになります（もう一方の対称な条件も同様）。このアイデアに基づき、検定は以下のように構成されています。

仮説の定式化: 帰無仮説 $H_0$ を「$P(M(D_1)\in E) \le e^{ϵ},P(M(D_2)\in E)$」とし、対立仮説 $H_1$ を「$P(M(D_1)\in E) > e^{ϵ},P(M(D_2)\in E)$」と定めます。直観的には、$H_0$は「アルゴリズムはϵ-差分プライバシーを満たしている（少なくともこの$E$に関しては）」という状況、$H_1$は「プライバシー違反が生じている」という状況を表します。検定の目的は$p$値が十分小さい場合に$H_0$を棄却し、$H_1$を支持することです。

サンプリング: Mに対し、$D_1$と$D_2$それぞれで独立に$n$回の試行を行います。各試行で得られた出力をそれぞれ$O1[1..n]$, $O2[1..n]$に記録し、事象$E$が起きたかどうかを数えます（$c_1 = |{i \mid O1[i] \in E}|$, $c_2 = |{i \mid O2[i] \in E}|$）。この $c_1, c_2$ は、$D_1$側・$D_2$側でイベント$E$が発生した「成功回数」と見なせます。各試行は互いに独立と近似できるため、$c_1$はパラメータ$p_1 = P(M(D_1)\in E)$の二項分布$\text{Bin}(n, p_1)$に、および$c_2$は$p_2 = P(M(D_2)\in E)$の$\text{Bin}(n, p_2)$にそれぞれ従うと考えられます。

p値の計算: 帰無仮説$H_0$の下では $p_1 \le e^{ϵ} p_2$ が成立しているはずですが、最もギリギリのケースとして $p_1 = e^{ϵ} p_2$（許容上限）と置いて検定統計量の分布を導出します。このとき、$p_1$と$p_2$は等しくはないものの定数倍の関係にあります。そこで工夫として、まず観測された$c_1$をスケーリングして疑似的なサンプル数 $c_1'$ を生成します。具体的には、$c_1$ 個の事象発生をそれぞれ独立に確率 $1/e^{ϵ}$ で「採用」する試行を行い（$\text{Binomial}(c_1,;1/e^{ϵ})$に従う乱数として$c_1'$を取得）、これによって期待値$\mathbb{E}[c_1'] = c_1/e^{ϵ}$と調整します。直観的には、$D_1$側の観測成功数$c_1$を $e^{ϵ}$ 倍減らすことで、$H_0$下で期待される成功数に近づける操作です。次に、$c_1'$と$c_2$の合計 $s = c_1' + c_2$ を求めます。帰無仮説の想定では「$D_1$側の**（調整後）成功確率**$p_1' = p_1/e^{ϵ}$ と $D_2$側の成功確率$p_2$は等しい（$p_1' = p_2$）」とみなせるため、この状況で「全体$s$個の成功のうち$D_1$側で$c_1'$個以上の成功が起きる確率」を計算します。これは超幾何分布（hypergeometric distribution）の累積分布関数を用いて、$P(C_1' \ge c_1' \mid C_1' + C_2 = s)$ として表せます。具体的には、母集団サイズ $N=2n$ 中に成功が $s$ 個存在し、その中からサイズ $n$ の$D_1$側サンプルで $c_1'$ 個以上の成功を得る確率であり、以下のように計算されます:

P(C1′​≥c1′​∣C1′​+C2​=s)=1−FHypergeom​(c1′​−1∣N=2n,K=n,s),

ここで $F_{\mathrm{Hypergeom}}(x \mid N, K, s)$ は超幾何分布における累積分布関数（$x$以下になる確率）です。したがって $1 - F_{\mathrm{Hypergeom}}(c_1'-1 \mid 2n, n, s)$ は「$c_1'$以上になる確率（右裾確率）」を表します。この値は、$H_0$が成り立つ場合にのみ未知の$p_1, p_2$に依存しない正しいp値になります（$p_1 < p_2$の場合はこの値よりもさらに小さくなることが証明できます）。以上をアルゴリズム2の疑似コードで示すと、p値計算部分は以下の通りです:

function pvalue(c1, c2, n, ϵ):
    c1_sampled = Binomial(c1, 1/e^ϵ)      // c1 を 1/e^ϵ スケールダウン
    s = c1_sampled + c2
    p = 1 − Hypergeom.cdf(c1_sampled − 1 | 2n, n, s)  // 超幾何分布で右裾確率
    return p


ここで Hypergeom.cdf(x | 2n, n, s) はSciPyの記法に倣い、母集団サイズ $2n$、抽出サイズ $n$、成功数合計 $s$ の超幾何分布における累積分布関数（値$\le x$となる確率）を表しています。このアルゴリズムにより、与えられた観測値 $(c_1, c_2)$ に対する片側検定のp値が計算されます。

両側の検定: 上記は $P(M(D_1)\in E)$ が大きすぎる場合（片側）を検定するp値 $p_{\top}$ に相当しますが、差分プライバシー違反は対称的にもう一方のケース（$P(M(D_2)\in E)$ が大きすぎる場合）も考えられます。したがってアルゴリズム2では、引数の $(c_1, c_2)$ を入れ替える形で再度p値を計算し $p_{\bot}$ として取得します。具体的には p_top = pvalue(c1, c2, n, ϵ) と p_bottom = pvalue(c2, c1, n, ϵ) の両方を求めます。こうして2種類の片側検定結果を用意し、前述の通り小さい方のp値をもって「差分プライバシー違反の有意性」と見なします。

分布の近似と分散低減: 上記p値計算では、$c_1$からのサンプリング（Binomial抽出）に乱数を用いています。これは帰無仮説下での $c_1'$ 分布をシミュレートする一種のランダム化手法ですが、この乱数により個々のp値計算結果にはばらつきが生じます。論文では分散を低減するため、複数回このp値計算を繰り返して平均を取ることが提案されています。すなわち、同じ入力データ $(c_1, c_2)$ に対し pvalue 関数を何度も実行し、その結果を平均することで安定した推定値とします。

以上がHypothesisTestにおけるp値計算の仕組みです。アルゴリズム2全体としてまとめると、入力として渡された $n, M, args, ϵ, D1, D2, E$ に対し、まず $M(D1)$と$M(D2)$を$n$回ずつ実行して$O1, O2$を収集し（行6–9）、次に上記の pvalue 計算を両方向で行い（行10–11）、2つのp値 $p_{\top}, p_{\bot}$ を返します。返されたp値が十分小さい（例えば有意水準$\alpha=0.05$以下など）場合、対応する仮説（$H_1$）すなわち差分プライバシー違反が統計的に有意であると判断します。

なお、本検定手法はフィッシャーの正確検定（Fisher’s exact test）に類似しています。フィッシャーの検定では2つの独立なベルヌーイ試行（例えば薬効あり/なしの二群比較）における成功率差を検出するため、超幾何分布に基づくp値計算を行いますが、本手法ではそれを発展させ、成功確率比が高々$e^{ϵ}$であるという制約付きで検定を行っていると言えます。超幾何分布によるp値計算は母数が未知でも正確な値を与えるため、このように**分布に頼らない検定（ノンパラメトリック検定）**として差分プライバシーの違反検知に適用できています。

3. Event Selection（アルゴリズム3、検索空間の構築とスコア選択）

上記の仮説検定は、事前に特定の出力事象 $E$ が与えられればその是非を判定できます。しかし実際には、どのような$E$が最も差分プライバシー違反を顕在化させるかは分からないため、**EventSelector（イベント選択）モジュールがそれを探索します。アルゴリズム3では、入力候補の各$(D_1, D_2, args)$について、出力の型に応じた様々なイベント集合 $S$**を定義し、それぞれに対してp値を試算して、最も有望なイベント$E$を選び出します。

◆ 出力型に応じたイベント候補の空間 $S$の構築:
メカニズムMの出力 $\omega$ がどのような形式（型）かによって、考慮すべきイベント$E$の種類が異なります。論文では以下のケースに分けて $S$ を定義しています。

(1) 固定長リスト（カテゴリ値）: 出力$\omega$が固定長$l$のカテゴリ値（離散値）のリストの場合です。例えばヒストグラム出力（固定長ベクトル）や、複数の真偽値を返すアルゴリズムなどが該当します。この場合、まず基準となる出力$\omega_0$を用意します。$\omega_0$はMに無限大プライバシー予算（$ϵ=\infty$）を与えてノイズ無しで実行した出力、つまり入力データに対する「真の回答」に相当するものです。この$\omega_0$と通常実行時の出力$\omega$との差分をとらえてイベントを定義します。具体的には、$\omega$と$\omega_0$とのハミング距離（異なる要素の数）を $t(\omega)$ と記し、**「ハミング距離が$k$である」**というイベント集合

Ek​={ω∣t(ω)=k},k=0,1,…,l

を候補とします。これは「ノイズによっていくつの出力成分が元の値から変化したか」に注目するものです。また、もう一つの種類のイベントとして、出力内の特定の値の出現回数に注目するものがあります。例えば出力リスト中にあるカテゴリ値$\mathit{value}_i$が存在するとき、その個数が$k$である事象

Ei,k​={ω∣ω.count(valuei​)=k},k=0,1,…,l

を定義します。全てのカテゴリ値$i$についてこのような$E_{i,k}$を用意し、先のハミング距離に関する集合と合わせて $S$ とします。例えば出力が真偽値リストの場合、「Trueの個数が$k$個である」というイベントがこれに当たります。

(2) 可変長リスト（カテゴリ値）: 出力が長さ可変のリストで、各要素がカテゴリ値である場合です。この場合は上記(1)の方法に加え、「出力長が$k$である」というイベント

Elen=k​={ω∣ω.length=k}

も候補に加えます。例えば疎ベクトル法（後述のSVT）の出力は可変長のTrue/False列になりますが、長さ（Trueを出力した回数）はプライバシー使用量と関係するため重要なイベントとなり得ます。なお(2)の場合、最終的な$S$はこの出力長イベント集合と、(1)で構築した固定長リストの場合の$S$を合併したものとして扱われます。

(3) 固定長ベクトル（数値）: 出力が固定長$m$の数値リスト（実数ベクトル）の場合です。例えばノイズ付きの実数統計量を複数返すアルゴリズム（Noisy Maxの正解版は最大値のインデックスのみ返しますが、不正版では数値を返す、Histogramは固定長数値ベクトルを返す、など）。この場合は連続値となるため、値の範囲に基づくイベントを構築します。具体的には以下のような種類があります:

各要素について「$\omega[i] \in (a,b)$である」というイベント（$i=1,\dots,m$ かつ 任意の区間$(a,b)$）。

全体の平均について「$\text{avg}(\omega) \in (a,b)$」というイベント。

最小値について「$\min(\omega) \in (a,b)$」というイベント。
これらはそれぞれ $a<b$ を満たす任意の実数区間$(a,b)$に対して定義されます。実装上は離散的な候補に絞る必要がありますが、出力値の分布から有望なしきい値をいくつか選んで区間を構成するなどのアプローチが考えられます。論文では詳細な生成方法には触れていませんが、実験では自動的に適切な区間が探索され、差分プライバシー違反が検出されています。

(4) 可変長リスト（数値）: 出力が可変長の数値リストの場合です。例えばプライバシー保護された公開リストで長さがデータ依存で変わり得る場合など。このケースでは、可変長カテゴリの場合と同様に「出力長が$k$」というイベント$E_{\text{len}=k}$を考慮する必要があります。また、出力の各要素が実数なので(3)のイベントとも組み合わせる必要があります。論文では、ケース(3)のイベント集合とケース(2)の長さイベント集合の和集合を取ったものを$S$とすると述べられています。

(5) 混合型（カテゴリ＋数値）: 出力が一部はカテゴリ値、一部は数値という混合型の場合です。この場合、上記(1)～(4)のアイデアを組み合わせ、カテゴリ部分と数値部分の条件を組み合わせた直積イベントを構成します。例えば疎ベクトル法の変種で「True/Falseのリスト（可変長）だが、Trueの場合は閾値を上回った差分値も数値で出力する」といったケースでは、「Falseの個数が9個で、かつ最後の出力数値がある範囲に入る」といった複合条件がイベントとなり得ます。実際、論文中のiSVT4というアルゴリズムではこのケースであり、EventSelectorが選んだイベントは「出力にFalseが9回出現し、残り1つの数値出力が -2.4〜2.4 の範囲に入る」というものでした。このようにカテゴリ条件と数値条件を同時に満たすイベントを候補に含めます。

以上のようにして定義されたイベント集合 $S$ の中から、有望なものを見つけるのがEventSelectorの役割です。Algorithm 3では、各入力候補 $(D_1, D_2, args)$ に対してまず $S$ を生成し、M(D_1), M(D_2)をそれぞれ$n$回実行して出力系列 $O1, O2$ を得ます。そして二重ループで各イベント $E \in S$ を列挙し、$c_1, c_2$ をカウントした上で Algorithm 2 のp値計算を呼び出して $p_{\top}, p_{\bot}$ を得ます。この2つのうち小さい方（最も違反の可能性が高い方向）をスコアとして記録します。$S$内の全イベントを試したら、その中で最小のp値を与えたイベント（および対応する入力$(D_1,D_2,args)$）を選択します。

なお前述の通り、EventSelector内部のこの評価は探索的なものなので、選ばれた組合せはCounterExampleDetection（Algorithm 1）の主ルーチンに戻ってから改めてHypothesisTestで検定されます。EventSelectorは効率上、多数の候補を手早く評価するためにp値計算をスコア的に使っているイメージです。また、全イベントを機械的に列挙すると組合せ爆発の恐れがありますが、実際には$O1, O2$の分布を見ながら出現しないか極めて稀なイベントは除外するといった工夫も行われています（上述の$c_E$によるフィルタリング参照）。

以上により、EventSelectorは与えられた入力ペア候補ごとに「最も怪しい事象$E$」を発見し、さらに全入力候補の中から「最も有意にプライバシー違反を示す組合せ $(D_1,D_2,args,E)$」を選び出します。これを反例候補としてHypothesisTestに渡すことで、最終的な検定と反例出力が行われるのです。

4. Input Generation（アルゴリズム4、データベース候補と Symbolic Execution を用いたパラメータ生成）

差分プライバシー違反の検出力は、探索する入力ペア $(D_1, D_2)$ に大きく左右されます。InputGenerator（入力生成）モジュールでは、アルゴリズムMに与える隣接データベースのペアと補助引数を戦略的に選びます。ポイントは、汎用的かつ少ない知識で有望な入力を網羅的に生成することと、アルゴリズム固有の追加パラメータ（閾値や反復回数など）をプライバシーコストが大きくなりやすい値に設定することです。アルゴリズム4はそのために2段階の処理を行います。

(A) 隣接データベース候補 $(D_1, D_2)$ の生成: 論文では、クエリ応答ベクトルとしてのデータベース（例えばヒストグラムや質問応答の集合）が、どのように変化し得るかをパターン化して、隣接ペアの候補を作成しています。Table 1に示されたパターンは以下の通りです（各ベクトルは例として長さ5のクエリ回答列を示す）:

| カテゴリー名               | サンプル D₁              | サンプル D₂              |
|---------------------------|---------------------------|---------------------------|
| One Above                 | [1, 1, 1, 1, 1]          | [2, 1, 1, 1, 1]          |
| One Below                 | [1, 1, 1, 1, 1]          | [0, 1, 1, 1, 1]          |
| One Above Rest Below      | [1, 1, 1, 1, 1]          | [2, 0, 0, 0, 0]          |
| One Below Rest Above      | [1, 1, 1, 1, 1]          | [0, 2, 2, 2, 2]          |
| Half Half                 | [1, 1, 1, 1, 1]          | [0, 0, 0, 2, 2]          |
| All Above & All Below     | [1, 1, 1, 1, 1]          | [2, 2, 2, 2, 2]          |
| X Shape                   | [1, 1, 0, 0, 0]          | [0, 0, 1, 1, 1]          |

これらのカテゴリは、各クエリ応答（感度1）が隣接データベース間でどのように増減し得るかの典型を表しています。例えば「One Above」は一つのクエリ回答だけが+1増加（他は変化なし）、「One Below」は一つだけ-1減少を表します。「One Above Rest Below」は1つの回答が+1増加し他すべてが-1減少するパターン、「Half Half」はほぼ半数のクエリが増加・残り半数が減少するパターンです。「All Above & All Below」は全てのクエリが一方では増加・もう一方では減少する極端な差、最後の「X Shape」はD<sub>1</sub>では前半のクエリが1・後半が0、D<sub>2</sub>では逆に前半0・後半1という入れ替えパターンで、増加と減少が交差するケースです。これら7種類のカテゴリを、論文では入力長5および10の場合について用意し、それぞれ$D_1, D_2$の具体例を複数生成しています。このようにパターンを網羅することで、多様な差分プライバシー違反の形態に対応できるようにしています。各カテゴリは人間にとっても理解しやすい単純な形なので、検出された反例は「あるクエリだけが増えて他は全て減った場合にバグが生じる」等、アルゴリズムの弱点を直感的に捉える助けにもなります。

以上の候補ペア生成により、InputGeneratorはまずリスト candidates に様々な$(D_1, D_2)$候補を集めます。擬似コードではlen（入力長、例えば5や10）を指定して Empirical pairs of databases of length len を取得しています。そして各候補について後述のパラメータ生成を行い、$(D_1,D_2,args)$をInputListに追加していきます。

(B) 補助引数 args の生成（Symbolic Execution + MaxSMT）: アルゴリズムMがデータベース$D$以外に追加の引数（パラメータ）を取る場合、それらをどの値に設定するかも反例検出の成否に影響します。例えばSparse Vector Technique（疎ベクトル法、SVT）には閾値 $T$ や Trueを出力できる上限数 $N$ といったパラメータがあり、これらの値次第でプライバシー消費や出力挙動が変わります。InputGeneratorでは、このような引数を差分プライバシー違反が起きやすい方向に設定するため、カスタマイズされたシンボリック実行とMaxSMTソルバを用いた探索を行っています。

アルゴリズム4の ArgumentGenerator(M, D1, D2) の手順は以下の通りです:

ノイズ生成関連引数の設定 (args0) – まず、プライバシーメカニズム内部でノイズを制御する引数について、ノイズが最小になる値に設定します。例えばLaplaceノイズのスケールや分散を左右するパラメータがあれば、それを小さく（ノイズ量が減る方向に）選びます。SVTの例で言えば、$N$（Trueを許容する回数上限）はプライバシー予算配分に効くため、最小の1に設定します。ノイズが小さいほど出力分布の差異（$D_1$ vs $D_2$）がブレにくくなり、統計検定の分散が減って違反を検出しやすくなります。このように、まずは「ノイズ以外の要因で差が出る状況」を作るための引数設定を行います。

分岐差分を引き起こす制約生成 – 次に、残りの引数については、Mのソースコードを解析して「$D_1$の場合と$D_2$の場合で異なる分岐をとる」ことを促進する制約を集めます。具体的には、$M$のプログラムをシンボリック実行ツールでトレースします。$D_1$と$D_2$は具体値として与え、その他の引数（例えば閾値$T$や他のフラグなど）をシンボリック変数として実行します。この際、$M$内部の乱数サンプルは全て固定値（例:0）に設定しておきます。これは、ノイズによる分岐の不確実性を除き、$D_1$と$D_2$の構造上の違いによる条件分岐のみを解析するためです。プログラム中のif文やループの条件を辿り、$D_1$を入力した場合に真・偽となる条件と、$D_2$を入力した場合に真・偽となる条件を比較します。もし特定の条件式で評価結果が$D_1$と$D_2$で異なる（つまり片方は真、もう一方は偽）なら、その条件が指すパスの分岐で2つの実行が異なる経路を取ることになります。このような条件について、「その分岐の両側をそれぞれ実現するような引数設定を満たせ」という制約をシンボリック実行から取得します。平たく言えば、「$D_1$と$D_2$でできるだけ処理の流れが分かれるように引数を選べ」という制約群です。疎ベクトル法で言えば、閾値$T$の値によってどのクエリでTrue/Falseを返すかが決まり、その結果ループが早期終了するか否かなど分岐が変わります。そこで「ある$T$では$D_1$上はTrueだが$D_2$上はFalseになるように」などの条件を列挙していくイメージです。

MaxSMTソルバによる充足解探索 – 手に入れた制約集合は、一般にはすべてを同時に満たすことが難しい場合があります。シンボリック実行で大量の分岐条件が見つかると、それら全てを矛盾なく実現する引数は存在しないかもしれません。そこで、MaxSMT（Maximum Satisfiability Modulo Theories）ソルバを用いて、できるだけ多くの制約を満たす解を探します。MaxSAT/MaxSMTとは、与えられた論理制約のうち充足可能な最大数の制約を満たす解を求める手法です。擬似コードでは args1 = MaxSMT(constraints) として、この制約充足問題を解いて得られた引数値の割当てを取得しています。これにより、「$D_1$と$D_2$で可能な限り多くの分岐が異なる」という目的が達成されます。分岐がたくさん異なるほど、一方の入力でTrueになる回数やFalseになる回数などプライバシー使用に関わる挙動に差が出る可能性が高く、結果として差分プライバシー違反が起きやすくなります。

引数の統合と返却 – 最終的に、ステップ1で決めたノイズ関連引数args0と、ステップ3で得られた引数args1とを統合して返します。例えばSVTなら、ノイズ規模に関わる$N$は1に設定し（args0）、閾値$T$についてはMaxSMTで導かれた値（args1）を使う、といった具合に一つのargsにまとめます。

以上が ArgumentGenerator の流れです。InputGenerator（アルゴリズム4）は、前半(A)で用意した各データベース候補 $(D_1, D_2)$ に対してこの ArgumentGenerator を適用し、得られたargsと組にして InputList に追加していきます。結果として、多数の $(D_1, D_2, args)$ 候補が生成されます。Algorithm 1ではこの InputList を受け取り、前述の EventSelector へ渡すことで、最適な反例コンビネーションの探索へと進むわけです。

要するに、InputGeneration段階では一般的な入力変化のパターンを網羅しつつ、各アルゴリズム特有のパラメータはプライバシーコストを最大化しうる値に自動調整しています。プログラム解析（シンボリック実行）と論理ソルバ（MaxSMT）の力を借りている点でブラックボックステスト以上の知見を活用していますが、それでも対象アルゴリズムの内部実装に過度の制約は設けず、広範なアルゴリズムに適用可能な汎用性を保っています。

5. 各応用アルゴリズムに対する評価と実験（Noisy Max, Histogram, Sparse Vector）

論文では、本手法を用いて公開されている複数の差分プライバシーアルゴリズム実装を評価し、既知のバグを検出できること、そして正しい実装では違反が検出されないことを示しています。対象とされた主なアルゴリズムは、Noisy Max（複数クエリの最大値を差分プライベートに報告するアルゴリズム）、Histogram（ヒストグラム公開アルゴリズム）、Sparse Vector Technique (SVT)（疎ベクトル法；閾値判定を複数回行うアルゴリズム）です。それぞれについて、論文中で正しい実装と既知の誤った実装（プライバシー保証にバグのあるバリアント）の双方をテストし、本手法の検出結果を報告しています。

以下、各アルゴリズムごとに実験結果を概観し、本手法の有効性を確認します。なお結果は主に、テストした複数のϵ値に対するp値（最小の片側p値）の推移としてグラフ化され、正しい実装では主張されたϵ付近でp値が上昇し違反を示さなくなる一方、誤った実装では小さなϵでもp値が低いままとなる（違反の証拠が出続ける）ことが示されています。また検出された具体的な反例（入力ペアとイベント）の例も表形式で提示されています。

Noisy Max に対する評価

Noisy Maxは、一連のクエリ回答$Q[i]$の中から最大値のクエリを報告するアルゴリズムです。正しい差分プライバシー実装では各クエリ回答にラプラスノイズまたは指数ノイズを独立に加え、その中の最大値のインデックス（どのクエリが最大だったか）を返します。一方、誤った実装の例として、最大値そのもの（ノイズ付きの数値）を返してしまうものがあります。後者は一見些細な違いですが、実は出力空間が連続値に広がるためプライバシー予算の消費が増大し、正しいϵでは収まらなくなる既知のバグです。

提案手法による検定では、正しいNoisy Max実装（Laplace版およびExponential版）について、主張されたプライバシー予算ϵ₀（例えば0.2, 0.7, 1.5）を下回るテストϵでは容易に違反が検出されるが、ϵがϵ₀付近に達するとp値が上昇し違反のエビデンスが消えるという結果になりました。具体的に、ϵ₀=0.7の正実装をテストした場合、ϵ=0.6まではp値が極めて小さい（有意に違反を検出）が、ϵ≈0.7でグラフの線が跳ね上がりp値≈1に近づく様子が図2a,bに示されています。この挙動は理想的な結果と一致しており、ϵ₀未満では誤検知もなく、ϵ₀以上では違反を示さないことから、本ツールの検定精度の高さが示されています（点線が理論上の境界を示す）。

一方、誤ったNoisy Max（最大値そのものを返す実装）では、p値の挙動が明らかに異なりました。Laplaceノイズ版の誤実装では、例えばϵ₀=0.2に対しテストϵ≈0.4になってようやくp値が上昇しはじめ（違反が緩和される）という具合で、主張ϵ₀=0.2では全くプライバシー保証が守れていないことが検出されています。ϵ₀=0.7や1.5の場合に至っては、テストでϵを最大2.2程度まで上げてもなおp値≈0のままで線がほとんど描画されないほどであり、事実上「非常に大きなϵでなければプライバシー違反が解消されない」、すなわち実際のプライバシーコストが極めて高いことを示しています。図2c,dでは、誤実装に対する各ϵ₀の線が理論値よりはるか右側（大きなテストϵ側）で立ち上がっており、例えばϵ₀=1.5の場合はグラフ上ほぼ水平で違反し続けています。著者らは、この誤実装が実際には $ϵ_0 \cdot |Q|/2$（|Q|はクエリ数）程度の差分プライバシー性しか持たないことを指摘しており、実験結果もそれを裏付けています。

検出された具体的反例として、例えば「Laplace版誤Noisy Max」では入力$D_1$を全クエリ値=1、$D_2$を全クエリ値=0にした場合に「出力が負の値になる」というイベントが違反の証拠として選ばれています。正しい実装なら出力はインデックス（1以上の整数）なので負になることはありませんが、誤実装ではノイズで負になる可能性があります。この**「$\omega < 0$」**という事象$E$で $P(M(D_1)\in E)$ が大きく異なり（$D_1$は常に最大値=1+ノイズなので負になる確率が小さいが、$D_2$は常に0+ノイズなので負になる確率が高い）、プライバシー違反が示されました。同様にExponential版誤Noisy Maxでも「$\omega < 1.0$」という閾値イベントが選ばれています。これらは直観的にも、本来出力しないはずの異常値が出力されること自体が差分プライバシー破れに繋がっている例と言えます。

Histogram に対する評価

Histogramアルゴリズムは、データベースのヒストグラム（各カテゴリの出現数）にノイズを加えて公開するシンプルな手法です。入力は元のヒストグラム（固定長ベクトル）で、出力は同じ次元のノイズ付ヒストグラムです。正しい実装では各ビンに独立なLaplace(1/ϵ₀)ノイズを加えます。誤った実装例として、感度の扱いを間違えLaplace(ϵ₀)（分散が大きすぎる！※通常Lap(b)はbが小さいほどノイズ小）を加えてしまうケースが挙げられています。これは直感に反し「ϵ₀が小さいほどノイズが小さい」という設定になってしまい、実際には主張ϵ₀の逆数が真のプライバシー係数となります。例えばϵ₀=0.2なら本来は大きなノイズが必要なのに誤実装は極小ノイズしか加えず、結果「1/0.2=5-差分プライバシー」程度の弱い保証しかない、ということになります。

実験では、正しいHistogram実装についてNoisy Max同様、主張ϵ₀ごとに線グラフがϵ₀付近で立ち上がることが確認されました（図3a）。一方、誤実装ではϵ₀<1の場合に厳しい違反が検出されています。例えばϵ₀=0.2, 0.7では対応する真のプライバシー係数が5, ≈1.43と大きいため、図3bにてそれらの線はテストϵ=0.2, 0.7では全く上昇せず、はるか高いϵでようやく立ち上がる様子が示されています。実際、ϵ₀=0.2のケースではテストϵ≈0.6付近まで違反検出が続き、ϵ₀=0.7でも1を超えるϵでやっとp値が上がっています。これは期待通りで、誤実装の真のプライバシー保証はそれぞれ1/ϵ₀（=5や≈1.43）であり、ツールはその値より少し低いϵで違反を検出しなくなる（線が上がる）ことを確認できます。興味深いのはϵ₀=1.5の場合です。この場合真のプライバシー係数は2/3 ≈0.67と主張より小さく、つまりアルゴリズムは「過剰にプライバシーを守っている」状況になります。実験結果でも、ϵ₀=1.5の誤実装に対しテストϵ≈0.6で線が上昇しており、逆に言えば主張ϵ₀=1.5より厳しい0.6差分プライバシーすら守っている可能性を示唆しています。このように、本手法は誤実装が必ずしも「プライバシー漏れ過多」だけでなく「過剰なノイズで本来よりプライバシーが高い」ケースでも、その精度限界内で検出・評価できることが分かります。

実際に得られた反例の例では、「Laplace(ϵ₀)を使った誤Histogram」に対し、$D_1$を全ビン=1、$D_2$を一つのビンだけ2に増やした隣接ペアで**「出力ヒストグラムの最初のビンが1.0未満になる」**というイベントが選ばれています。これは、正しい実装なら最初のビンには平均1（元のカウント）±十分大きなノイズが乗るので0付近になる確率は適切ですが、誤実装ではノイズが小さいため$D_2$（最初のビンが2）と$D_1$（1）の出力分布がはっきり分かれ、特に$D_2$では「出力<1」の確率が極小になる（元が2でノイズ小なので出力が1以上である場合が多い）といった違反が表れます。このように、Histogramのバグも確実に検出されています。

Sparse Vector Technique (SVT) に対する評価

**Sparse Vector Technique (SVT)**は、設定した閾値$T$に対し「入力クエリの値が上回っているか否か」を差分プライベートに逐次判定するアルゴリズムです。SVTの特徴は、閾値判定に関して「閾値以下であれば何度答えてもプライバシーコスト0」という点にあります。一方、閾値を超えた（Trueとなる）回答は高々$N$回までしか許されず、それ以上Trueを出すときは停止します。この性質により、許容回数$N$までのTrueと無制限のFalseを出力します。SVTは強力な手法ですが、その分実装も繊細で、多くの変種アルゴリズムが提案されては実は間違っていたと判明する事例が多数報告されています。論文では、正しいSVT実装（Lyuらによる証明済み実装 [28]）と、既知の主要な間違った実装（4種類、論文中ではiSVT1～4と呼称）をテストしています。

SVT 正実装 [28]: プライバシー予算ϵ₀を閾値用（η1のノイズ）とTrue値出力用（各η2のノイズ）に半分ずつ割り当て、Trueを$N$回までしか出さないバージョンです。実験では、他の正実装と同様に、主張ϵ₀の値ごとに線がϵ₀付近で立ち上がり、ツールが「正しくプライバシーが守られている」ことを確認しています（図4aの各線はほぼϵ₀と同じ位置で上昇）。したがって、本手法はSVTのように複雑なアルゴリズムでも誤検出せず正確に動作しました。

iSVT 1 [38]: 閾値判定（η1）とクエリ値（η2）のどちらにもノイズを加えない、かつTrue出力回数に制限が無い最悪の変種です。もちろん差分プライバシーは全く成立せず、「有限のϵ₀ではどんな値でも満たさない」アルゴリズムです。本ツールでも、ϵ₀=0.2, 0.7, 1.5の各ケースでテストしたϵの範囲すべて（例えば0〜2.2まで）においてp値が0のまま上昇しない、つまり常に違反が検出された状態となりました（図4bは全ϵで線が下に張り付いている）。この結果は当然ですが、ツールが確実に「どんなϵでもアウトである」ことを示す反例を提示できたことを意味します。実際に選ばれた反例は、10長の入力で$D_1$の全要素=1、$D_2$が半分0・半分2という組合せ（X Shapeの拡張）に対し**「出力がノイズ無し実行とまったく同じになる」（$t(\omega)=0$）**というイベントでした。ノイズ皆無のため当たり前ですが、$D_1$と$D_2$で出力が異なる箇所が一切なくなる確率が極端に違い（$D_1$ではFalse連発、$D_2$ではTrueも出続け出力列が異なる）、即座にバレるというわけです。

iSVT 2 [11]: True出力の上限$N$が無制限である以外は正実装と同じ（ノイズはある）変種です。Trueを出し放題にすると、$N$に比例してプライバシー漏洩が累積するため、このアルゴリズムも有限ϵ₀ではプライバシーを満たしません。ツールの結果もiSVT1に近く、ϵ₀=0.2, 0.7, 1.5に対しそれぞれ「ϵ≈0.5まで」「ϵ≈2.1まで」「ϵ≈3.0まで」の範囲でp値が上がらない（違反し続けている）ことが確認されています。図4cでは例えばϵ₀=0.2の場合、テストϵ=0.5を超えてようやく線が上がり始めています。実際には上限なくTrueを出せると、理論的にはϵ→∞でしかプライバシー保証が成立しないため、ツールもかなり大きな範囲まで違反を検出し続けました。反例の例としては、iSVT2では$D_1$と$D_2$に「前半1・後半0」vs「前半0・後半1」というX Shapeパターンを与え、イベントに**$t(\omega)=9$**（10個中9箇所異なる出力）というものが選ばれています。True出力無制限のため、$D_2$（後半クエリが高いためTrueがたくさん出る）では出力列がほぼ$D_1$（前半クエリ高い）とまったく異なる長さ/位置になることが多く、9箇所も相違が出るという極端な差が検出できたわけです。

iSVT 3 [27]: True上限$N$があるものの、各クエリへのノイズη2のスケールが誤って一定（$N$によらず）になっている変種です。本来は$N$が大きいほど一つ一つのTrue判定で消費するプライバシー予算を小さくすべきですが、この実装ではそれをせず、結果として実際のプライバシーコストが $(1+6N)/4 * ϵ₀$ になると報告されています。例えば$N=1$なら$(1+6*1)/4=7/4=1.75$倍、$N=2$なら$(1+12)/4=13/4=3.25$倍、などと肥大化します。ツールの結果は見事にこれを捉えており、図4dで各ϵ₀に対し理論値より少し手前で線が立ち上がっています。例えばϵ₀=0.2（$N=1$）では真のプライバシー費用は0.35ですが、線は0.3付近で上昇し始めています。ϵ₀=0.7（理論1.225）の場合は線が1.1付近、ϵ₀=1.5（理論2.625）では2.3付近で上昇しています。いずれも過大なプライバシーコストを検出し、理論値の少し下（厳しめ側）で検出限界となっていることが示されています。つまり、本ツールは実装のバグによる「必要プライバシー予算の過小見積り」を具体的数値込みで指摘できたことになります。このケースの反例もiSVT2同様、X Shapeパターン入力に対し $t(\omega)=0$（出力がノイズ無し実行と同じ）というイベントが検出されています。ノイズスケールが小さすぎるため、True/Falseの判定結果が常に決まりきってしまい、$D_1$と$D_2$で出力が全く同じになる（例えばどちらも最初のクエリだけTrueであとはFalse…等）確率が異常に高くなることを捉えたものと考えられます。

iSVT 4 [36]: Trueの場合に閾値を超えた実際のノイズ付き値（数値）を出力してしまう変種です。本来SVTはTrue/Falseのみ出力すべきですが、この実装はTrueのときに「$q_i + η2$の値そのもの」を返します。結果、出力がFalse/数値の混合列となり、Falseの個数や数値の大きさから追加の情報が漏れることになります。著者らは「任意の有限ϵ₀ではプライバシーを満たさない」ケースと述べています。しかしiSVT1や2と異なり、False/True自体の挙動はそこまで違わない（True回数も$N$で制限されノイズもある）ため、非常に低い確率でのみ違反が発生する「ほぼ正しい」実装とされています。図4eでは線が他よりもノイズが多く見えますが、それでも各ϵ₀の線は主張より遅れて上昇しており、ϵ₀=0.2, 0.7, 1.5の全てでプライバシー破れを検出しています。ただしp値が極端に0に張り付くわけではなく、一部区間で0でない値も見られるため、違反の頻度がごく低いこともうかがえます。ツールはこのケースでも統計的に有意な違反を捉え、「ϵ₀差分プライバシーではない」ことを結論付けました。EventSelectorが選んだイベントは先述の通り「Falseが9回、最後の数値出力が(-2.4,2.4)に入る」という複合条件で、False/Trueの混合出力から情報を引き出す巧みなものです。$D_1$として全クエリ0、$D_2$として全クエリ0（常にFalseしか出ない）を与えれば、本来Trueは出ないはずですが、iSVT4ではノイズ値そのものを吐くせいでたまにFalseの代わりに0近辺の数値が漏れて出力されることがあり、それを検知した例と推察されます。

以上のように、Noisy Max, Histogram, SVTそれぞれの正しい実装では本ツールのp値グラフは理論通りの挙動を示し、誤った実装では著名なバグ（過小ノイズ、出力内容の誤り、回数制限の欠如等）に起因する差分プライバシー違反を全て検出できました。さらに、理論解析で判明していた「実際にはϵ₀を満たさないがϵ=Xなら満たす」といった境界値もグラフから読み取れる精度であり、反例として提示される $(D_1, D_2, E)$ も人間がアルゴリズムの欠陥を理解しやすい形で出力されています。例えば表2（論文中のTable 2）に示された反例一覧では、前述のNoisy MaxやHistogram、SVT各バリアントに対し、それぞれ「$D_1$をこう、$D_2$をこうしたら、このイベントで違反」という具体例が列挙されています。本解説中でもいくつか触れた通り、簡潔な入力差分（1や0を用いた短いベクトル）と分かりやすいイベント条件（値が負になる、出力長が違う、等）が多く、開発者が見てもバグの所在を突きやすい内容になっています。

おわりに

本稿では「Detecting Violations of Differential Privacy」の提案手法について、アルゴリズム構成と統計手法を中心に詳細に説明しました。セミブラックボックスなアプローチにより、対象アルゴリズムを大量実行して統計的仮説検定を行うことで、証明負担なく自動的にプライバシー違反の反例を発見できる点が本手法の強みです。実験結果からも、既知の不備あるアルゴリズムを数秒で検出し反例を提示できる有用性が示されています。今後は、極めて低確率の違反（現在のサンプル数では捉えにくいケース）や差分プライバシーの他の定義（局所DPなど）への拡張が課題として挙げられています。いずれにせよ本研究は、差分プライバシーアルゴリズムの実装検証に新たな視点と実用的ツールを提供するものであり、プライバシー保護技術の開発プロセスに大きく貢献するものと言えるでしょう。