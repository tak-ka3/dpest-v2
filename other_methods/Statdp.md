# StatDP: 統計的テストによる差分プライバシー違反の検出

**出典**: Ding, Z., Wang, Y., Wang, G., Zhang, D., & Kifer, D. (2018). Detecting Violations of Differential Privacy. *ACM CCS 2018*.

## 手法の概要

StatDPは、差分プライバシーアルゴリズムの実装が主張するプライバシー保証を実際に満たしているかを検証するための統計的テスト手法です。本手法は、アルゴリズムの実装をセミブラックボックス方式で多数回実行し、その出力分布の違いに統計的検定を適用することで、差分プライバシー違反（プライバシー保証の不成立）を検出し、人間が理解しやすい反例（カウンターエグザンプル）を自動生成します。

### 主要な特徴

1. **セミブラックボックスアプローチ**: アルゴリズムの内部構造に過度に依存せず、入出力の統計的性質から違反を検出
2. **統計的仮説検定**: Fisher's Exact Testの拡張版を用いた厳密な検定
3. **自動反例生成**: 違反が検出された場合、具体的な入力ペア $ (D_1, D_2) $ と出力事象 $ E $ を提示
4. **高速検出**: 複雑な証明を必要とせず、既知のバグを数秒〜数分で検出

### 主要コンポーネント

StatDPは4つの主要アルゴリズムから構成されます（Algorithm 1-4）:

1. **CounterExampleDetection（全体制御）**: 入力生成、イベント選択、仮説検定を統合
2. **HypothesisTest（仮説検定）**: 確率的変換と超幾何分布を用いたp値計算
3. **EventSelector（イベント選択）**: 出力型に応じた候補事象の探索とスコアリング
4. **InputGenerator（入力生成）**: 隣接データベースペアとパラメータの戦略的生成

## 手法の詳細を説明するにあたって必要な知識

### 1. 差分プライバシーの基礎

**定義**: メカニズム $ M $ が $ \varepsilon $ -差分プライバシーを満たすとは、任意の隣接データベース $ D_1, D_2 $ （1レコードのみ異なる）と任意の出力事象 $ E $ について、以下が成立することです:

$$P(M(D_1) \in E) \leq e^{\varepsilon} \cdot P(M(D_2) \in E)$$

**隣接データベース**: 1つのレコードの追加・削除・変更によってのみ異なる2つのデータベース。感度1のクエリでは、各クエリの応答値が高々1だけ異なります。

### 2. 統計的仮説検定の基礎

**帰無仮説 $ H_0 $ と対立仮説 $ H_1 $ **:
- $ H_0 $ : アルゴリズムは $ \varepsilon $ -差分プライバシーを満たす（ $ P(M(D_1)\in E) \leq e^{\varepsilon} P(M(D_2)\in E) $ ）
- $ H_1 $ : アルゴリズムは違反している（ $ P(M(D_1)\in E) > e^{\varepsilon} P(M(D_2)\in E) $ ）

**p値**: 帰無仮説が正しいと仮定したときに、観測されたデータまたはそれより極端なデータが得られる確率。p値が小さい（例: < 0.05）場合、帰無仮説を棄却し違反を検出します。

**Fisher's Exact Test**: 2つの独立なベルヌーイ試行における成功率の差を検出するノンパラメトリック検定。超幾何分布に基づくp値計算を行います。

### 3. StatDPで使用される主要な統計分布

**二項分布 $ \text{Binomial}(n, p) $ **: $ n $ 回の独立試行で成功確率 $ p $ のとき、成功回数の分布。

**超幾何分布 $ \text{Hypergeometric}(N, K, n) $ **: 母集団サイズ $ N $ 、成功数 $ K $ 、抽出サイズ $ n $ のときの成功数の分布。StatDPでは以下の形で使用:
- 母集団サイズ: $ 2n $ （$D_1 $ 側と $ D_2 $ 側の合計試行数）
- 成功数合計: $ s = c_1' + c_2 $ （調整後の成功数合計）
- 抽出サイズ: $ n $ （片側の試行数）

### 4. 確率的変換（Probabilistic Transformation）

StatDPの核心的アイデア: 観測された成功回数 $ c_1 $ を確率 $ 1/e^{\varepsilon} $ でサンプリングして $ c_1' $ を得ることで、期待値を $ \mathbb{E}[c_1'] = c_1/e^{\varepsilon} $ に調整します。これにより、帰無仮説下で $ p_1' = p_1/e^{\varepsilon} = p_2 $ という等確率条件が成立し、Fisher's Exact Testを適用可能にします。

### 5. シンボリック実行とMaxSMT

**シンボリック実行**: プログラムを実際の値ではなくシンボリック変数で実行し、各パスの実行条件（path constraint）を論理式として収集する技術。

**MaxSMT（Maximum Satisfiability Modulo Theories）**: 与えられた論理制約のうち、充足可能な最大数の制約を満たす解を求めるソルバ。StatDPでは、 $ D_1 $ と $ D_2 $ で可能な限り多くの分岐が異なるようなパラメータ設定を探索するために使用します。

## 手法の詳細

### 1. 全体アーキテクチャ（Algorithm 1: CounterExampleDetection）

Algorithm 1は、メカニズム実装 $ M $ とその主張するプライバシーパラメータ $ \varepsilon $ を受け取り、以下の3ステップで反例を検出します:

#### ステップ1: 入力候補の生成（InputGenerator → Algorithm 4）

InputGeneratorは、隣接データベースペア $ (D_1, D_2) $ とパラメータ $ args $ の組を複数生成します（InputList）。

**設計原則**:
- **単純性**: 開発者が理解しやすいよう、小規模で単純なデータペアを生成
- **効率性**: 多数回実行されるため、データサイズを小さく抑える
- **網羅性**: 典型的な隣接関係のパターンを体系的にカバー

#### ステップ2: イベント選択（EventSelector → Algorithm 3）

InputList内の各候補 $ (D_1, D_2, args) $ について:

1. $ M(D_1, args) $ と $ M(D_2, args) $ を各 $ n $ 回実行し、出力系列 $ O1[1..n] $ , $ O2[1..n] $ を収集
2. 出力型に応じた候補イベント集合 $ S $ を構築（詳細は後述）
3. 各イベント $ E \in S $ について:
   - イベント発生回数をカウント: $ c_1 = |\{i \mid O1[i] \in E\}| $ , $ c_2 = |\{i \mid O2[i] \in E\}| $
   - HypothesisTest（Algorithm 2）を呼び出してp値を計算
   - 最小p値とその際の $ (D_1, D_2, args, E) $ を記録
4. 全候補中で最もp値の小さい組合せを選択

**多重比較への対処**: EventSelector内の評価は探索的なため、選ばれた組合せは改めて新しいサンプルで検定し直します（p値ハッキングの回避）。

**稀なイベントのフィルタリング**: $ c_E = c_1 + c_2 < 0.001 \cdot n \cdot e^{\varepsilon} $ の場合、そのイベントをスキップ（ノイズが大きすぎて信頼できないため）。

#### ステップ3: 仮説検定（HypothesisTest → Algorithm 2）

選択された $ (D_1, D_2, args, E) $ について、改めて $ n $ 回ずつ実行して厳密な検定を実施:

1. 新しいサンプルで $ c_1, c_2 $ を収集
2. 両方向の片側検定を実行:
   - $ p_{\top} $ : 「 $ P(M(D_1)\in E) > e^{\varepsilon} P(M(D_2)\in E) $ 」の有意性
   - $ p_{\bot} $ : 「 $ P(M(D_2)\in E) > e^{\varepsilon} P(M(D_1)\in E) $ 」の有意性
3. $ \min(p_{\top}, p_{\bot}) $ を最終的な違反の証拠とする

**出力**: p値が有意水準（例: 0.05）未満なら、 $ (D_1, D_2, E) $ を反例として出力。そうでなければ違反なしと判定。

**セミブラックボックスの意味**: 基本的には入出力の統計のみを利用しますが、入力生成やパラメータ選択では部分的にソースコード解析（シンボリック実行）も活用します。

### 2. 仮説検定（Algorithm 2: HypothesisTest）

#### 基本アイデア

差分プライバシーの定義より、 $ M$ が $ \varepsilon $ -DPを満たすなら:
$$\frac{P(M(D_1)\in E)}{P(M(D_2)\in E)} \leq e^{\varepsilon}$$

違反を示すには、ある事象 $ E $ について上記の不等式が成立しないことを統計的に示す必要があります。

#### サンプリングと観測

1. $ M(D_1) $ と $ M(D_2) $ を各 $ n $ 回実行し、出力系列 $ O1[1..n] $ , $ O2[1..n] $ を収集
2. イベント $ E $ の発生回数をカウント:
   - $ c_1 = |\{i \mid O1[i] \in E\}| $ （ $ D_1 $ 側の成功回数）
   - $ c_2 = |\{i \mid O2[i] \in E\}| $ （ $ D_2 $ 側の成功回数）
3. 統計モデル:
   - $ c_1 \sim \text{Binomial}(n, p_1) $ where $ p_1 = P(M(D_1)\in E) $
   - $ c_2 \sim \text{Binomial}(n, p_2) $ where $ p_2 = P(M(D_2)\in E) $

#### p値計算の核心的アイデア: 確率的変換

**課題**: 帰無仮説 $ H_0: p_1 \leq e^{\varepsilon} p_2 $ の下で、 $ p_1 \neq p_2 $ のため直接Fisher's Exact Testを適用できない。

**解決策**: 確率的変換により等確率条件を作り出す:

1. **調整**: 観測成功回数 $ c_1 $ を確率 $ 1/e^{\varepsilon} $ でサンプリング
   $$c_1' \sim \text{Binomial}(c_1, 1/e^{\varepsilon})$$
   - 期待値: $ \mathbb{E}[c_1'] = c_1/e^{\varepsilon} $
   - 直感: $ D_1 $ 側の成功数を $ e^{\varepsilon} $ 倍縮小して $ D_2 $ と釣り合わせる

2. **合計成功数**: $ s = c_1' + c_2 $

3. **等確率条件の達成**: $ H_0 $ の最悪ケース $ p_1 = e^{\varepsilon} p_2 $ では:
   $$p_1' = p_1/e^{\varepsilon} = p_2$$
   つまり、調整後の成功確率が等しくなる

4. **超幾何分布によるp値計算**:
   $$p = P(C_1' \geq c_1' \mid C_1' + C_2 = s) = 1 - F_{\text{Hypergeom}}(c_1' - 1 \mid 2n, n, s)$$

   where:
   - 母集団サイズ: $ N = 2n $
   - 抽出サイズ: $ K = n $
   - 成功数合計: $ s = c_1' + c_2 $

#### アルゴリズムの疑似コード

```
function pvalue(c1, c2, n, ε):
    c1' ← Binomial(c1, 1/e^ε)              // 確率的変換
    s ← c1' + c2
    p ← 1 - Hypergeom.cdf(c1' - 1 | 2n, n, s)  // 超幾何分布の右裾確率
    return p

function HypothesisTest(M, D1, D2, E, n, ε):
    // サンプリング
    O1 ← [M(D1) for i in 1..n]
    O2 ← [M(D2) for i in 1..n]
    c1 ← count({O1[i] ∈ E})
    c2 ← count({O2[i] ∈ E})

    // 両方向の片側検定
    p_top ← pvalue(c1, c2, n, ε)        // D1側が大きすぎる場合
    p_bottom ← pvalue(c2, c1, n, ε)     // D2側が大きすぎる場合

    return (p_top, p_bottom)
```

#### 両側検定と分散低減

- **両方向の検定**: $ p_{\top} $ と $ p_{\bot} $ の両方を計算し、小さい方を違反の証拠とする
- **分散低減**: 確率的変換 $ c_1' $ のランダム性により p値にばらつきが生じるため、複数回計算して平均を取る

#### 特徴

- **ノンパラメトリック**: 超幾何分布による正確なp値計算（母数 $ p_1, p_2 $ が未知でも適用可能）
- **Fisher's Exact Testの拡張**: 成功確率比が高々 $ e^{\varepsilon} $ という制約下で検定を実行

### 3. イベント選択（Algorithm 3: EventSelector）

#### 目的

出力事象 $ E $ の空間は無限に存在するため、違反を最も顕著に示すイベントを効率的に探索する必要があります。

#### 出力型に応じたイベント候補空間 $ S $ の構築

メカニズムMの出力 $ \omega $ の型に応じて、考慮すべきイベント $ E$の種類が異なります:

**(1) 固定長リスト（カテゴリ値）**: 出力 $ \omega $ が固定長 $ l$のカテゴリ値（離散値）のリストの場合です。例えばヒストグラム出力（固定長ベクトル）や、複数の真偽値を返すアルゴリズムなどが該当します。この場合、まず基準となる出力 $ \omega_0 $ を用意します。 $ \omega_0 $ はMに無限大プライバシー予算（ $ ϵ=\infty $ ）を与えてノイズ無しで実行した出力、つまり入力データに対する「真の回答」に相当するものです。この $ \omega_0 $ と通常実行時の出力 $ \omega $ との差分をとらえてイベントを定義します。具体的には、 $ \omega $ と$\omega_0 $ とのハミング距離（異なる要素の数）を $ t(\omega) $ と記し、**「ハミング距離が $ k$である」**というイベント集合

Ek​={ω∣t(ω)=k},k=0,1,…,l

を候補とします。これは「ノイズによっていくつの出力成分が元の値から変化したか」に注目するものです。また、もう一つの種類のイベントとして、出力内の特定の値の出現回数に注目するものがあります。例えば出力リスト中にあるカテゴリ値 $ \mathit{value}_i $ が存在するとき、その個数が $ k$である事象

Ei,k​={ω∣ω.count(valuei​)=k},k=0,1,…,l

を定義します。全てのカテゴリ値 $ i$についてこのような $ E_{i,k} $ を用意し、先のハミング距離に関する集合と合わせて $ S $ とします。例えば出力が真偽値リストの場合、「Trueの個数が $ k$個である」というイベントがこれに当たります。

**(2) 可変長リスト（カテゴリ値）**: 出力が長さ可変のリストで、各要素がカテゴリ値である場合です。この場合は上記(1)の方法に加え、「出力長が $ k$である」というイベント

Elen=k​={ω∣ω.length=k}

も候補に加えます。例えば疎ベクトル法（後述のSVT）の出力は可変長のTrue/False列になりますが、長さ（Trueを出力した回数）はプライバシー使用量と関係するため重要なイベントとなり得ます。なお(2)の場合、最終的な $ S$はこの出力長イベント集合と、(1)で構築した固定長リストの場合の $ S$を合併したものとして扱われます。

**(3) 固定長ベクトル（数値）**: 出力が固定長 $ m$の数値リスト（実数ベクトル）の場合です。例えばノイズ付きの実数統計量を複数返すアルゴリズム（Noisy Maxの正解版は最大値のインデックスのみ返しますが、不正版では数値を返す、Histogramは固定長数値ベクトルを返す、など）。この場合は連続値となるため、値の範囲に基づくイベントを構築します。具体的には以下のような種類があります:

各要素について「 $ \omega[i] \in (a,b) $ である」というイベント（ $ i=1,\dots,m $ かつ 任意の区間 $ (a,b) $ ）。

全体の平均について「 $ \text{avg}(\omega) \in (a,b) $ 」というイベント。

最小値について「 $ \min(\omega) \in (a,b) $ 」というイベント。
これらはそれぞれ $ a<b $ を満たす任意の実数区間 $ (a,b) $ に対して定義されます。実装上は離散的な候補に絞る必要がありますが、出力値の分布から有望なしきい値をいくつか選んで区間を構成するなどのアプローチが考えられます。論文では詳細な生成方法には触れていませんが、実験では自動的に適切な区間が探索され、差分プライバシー違反が検出されています。

**(4) 可変長リスト（数値）**: 出力が可変長の数値リストの場合です。例えばプライバシー保護された公開リストで長さがデータ依存で変わり得る場合など。このケースでは、可変長カテゴリの場合と同様に「出力長が $ k$」というイベント $ E_{\text{len}=k} $ を考慮する必要があります。また、出力の各要素が実数なので(3)のイベントとも組み合わせる必要があります。論文では、ケース(3)のイベント集合とケース(2)の長さイベント集合の和集合を取ったものを $ S$とすると述べられています。

**(5) 混合型（カテゴリ＋数値）**: 出力が一部はカテゴリ値、一部は数値という混合型の場合です。この場合、上記(1)～(4)のアイデアを組み合わせ、カテゴリ部分と数値部分の条件を組み合わせた直積イベントを構成します。例えば疎ベクトル法の変種で「True/Falseのリスト（可変長）だが、Trueの場合は閾値を上回った差分値も数値で出力する」といったケースでは、「Falseの個数が9個で、かつ最後の出力数値がある範囲に入る」といった複合条件がイベントとなり得ます。実際、論文中のiSVT4というアルゴリズムではこのケースであり、EventSelectorが選んだイベントは「出力にFalseが9回出現し、残り1つの数値出力が -2.4〜2.4 の範囲に入る」というものでした。このようにカテゴリ条件と数値条件を同時に満たすイベントを候補に含めます。

以上のようにして定義されたイベント集合 $ S $ の中から、有望なものを見つけるのがEventSelectorの役割です。Algorithm 3では、各入力候補 $ (D_1, D_2, args) $ に対してまず $ S $ を生成し、M(D_1), M(D_2)をそれぞれ $ n$回実行して出力系列 $ O1, O2 $ を得ます。そして二重ループで各イベント $ E \in S $ を列挙し、 $ c_1, c_2 $ をカウントした上で Algorithm 2 のp値計算を呼び出して $ p_{\top}, p_{\bot} $ を得ます。この2つのうち小さい方（最も違反の可能性が高い方向）をスコアとして記録します。 $ S$内の全イベントを試したら、その中で最小のp値を与えたイベント（および対応する入力 $ (D_1,D_2,args) $ ）を選択します。

なお前述の通り、EventSelector内部のこの評価は探索的なものなので、選ばれた組合せはCounterExampleDetection（Algorithm 1）の主ルーチンに戻ってから改めてHypothesisTestで検定されます。EventSelectorは効率上、多数の候補を手早く評価するためにp値計算をスコア的に使っているイメージです。また、全イベントを機械的に列挙すると組合せ爆発の恐れがありますが、実際には $ O1, O2 $ の分布を見ながら出現しないか極めて稀なイベントは除外するといった工夫も行われています（上述の $ c_E $ によるフィルタリング参照）。

以上により、EventSelectorは与えられた入力ペア候補ごとに「最も怪しい事象 $ E$」を発見し、さらに全入力候補の中から「最も有意にプライバシー違反を示す組合せ $ (D_1,D_2,args,E) $ 」を選び出します。これを反例候補としてHypothesisTestに渡すことで、最終的な検定と反例出力が行われるのです。

### 4. 入力生成（Algorithm 4: InputGenerator）

#### 目的と設計方針

差分プライバシー違反の検出力は、探索する入力ペア $ (D_1, D_2) $ とパラメータ $ args $ の選択に大きく依存します。InputGeneratorは以下の方針で入力を生成します:

1. **汎用性**: アルゴリズム固有の知識に過度に依存しない
2. **網羅性**: 典型的な隣接関係のパターンを体系的にカバー
3. **効率性**: プライバシーコストが大きくなりやすいパラメータ設定を自動選択

#### (A) 隣接データベース候補の生成: 経験的パターン

クエリ応答ベクトルとしてのデータベースが、どのように変化し得るかをパターン化して隣接ペアを作成します（Table 1より）:

| カテゴリー名               | サンプル D₁              | サンプル D₂              |
|---------------------------|---------------------------|---------------------------|
| One Above                 | [1, 1, 1, 1, 1]          | [2, 1, 1, 1, 1]          |
| One Below                 | [1, 1, 1, 1, 1]          | [0, 1, 1, 1, 1]          |
| One Above Rest Below      | [1, 1, 1, 1, 1]          | [2, 0, 0, 0, 0]          |
| One Below Rest Above      | [1, 1, 1, 1, 1]          | [0, 2, 2, 2, 2]          |
| Half Half                 | [1, 1, 1, 1, 1]          | [0, 0, 0, 2, 2]          |
| All Above & All Below     | [1, 1, 1, 1, 1]          | [2, 2, 2, 2, 2]          |
| X Shape                   | [1, 1, 0, 0, 0]          | [0, 0, 1, 1, 1]          |

これらのカテゴリは、各クエリ応答（感度1）が隣接データベース間でどのように増減し得るかの典型を表しています。例えば「One Above」は一つのクエリ回答だけが+1増加（他は変化なし）、「One Below」は一つだけ-1減少を表します。「One Above Rest Below」は1つの回答が+1増加し他すべてが-1減少するパターン、「Half Half」はほぼ半数のクエリが増加・残り半数が減少するパターンです。「All Above & All Below」は全てのクエリが一方では増加・もう一方では減少する極端な差、最後の「X Shape」はD<sub>1</sub>では前半のクエリが1・後半が0、D<sub>2</sub>では逆に前半0・後半1という入れ替えパターンで、増加と減少が交差するケースです。これら7種類のカテゴリを、論文では入力長5および10の場合について用意し、それぞれ $ D_1, D_2 $ の具体例を複数生成しています。このようにパターンを網羅することで、多様な差分プライバシー違反の形態に対応できるようにしています。各カテゴリは人間にとっても理解しやすい単純な形なので、検出された反例は「あるクエリだけが増えて他は全て減った場合にバグが生じる」等、アルゴリズムの弱点を直感的に捉える助けにもなります。

以上の候補ペア生成により、InputGeneratorはまずリスト candidates に様々な $ (D_1, D_2) $ 候補を集めます。擬似コードではlen（入力長、例えば5や10）を指定して Empirical pairs of databases of length len を取得しています。そして各候補について後述のパラメータ生成を行い、 $ (D_1,D_2,args) $ をInputListに追加していきます。

(B) 補助引数 args の生成（Symbolic Execution + MaxSMT）: アルゴリズムMがデータベース $ D$以外に追加の引数（パラメータ）を取る場合、それらをどの値に設定するかも反例検出の成否に影響します。例えばSparse Vector Technique（疎ベクトル法、SVT）には閾値 $ T $ や Trueを出力できる上限数 $ N $ といったパラメータがあり、これらの値次第でプライバシー消費や出力挙動が変わります。InputGeneratorでは、このような引数を差分プライバシー違反が起きやすい方向に設定するため、カスタマイズされたシンボリック実行とMaxSMTソルバを用いた探索を行っています。

アルゴリズム4の ArgumentGenerator(M, D1, D2) の手順は以下の通りです:

ノイズ生成関連引数の設定 (args0) – まず、プライバシーメカニズム内部でノイズを制御する引数について、ノイズが最小になる値に設定します。例えばLaplaceノイズのスケールや分散を左右するパラメータがあれば、それを小さく（ノイズ量が減る方向に）選びます。SVTの例で言えば、 $ N$（Trueを許容する回数上限）はプライバシー予算配分に効くため、最小の1に設定します。ノイズが小さいほど出力分布の差異（ $ D_1 $ vs $ D_2 $ ）がブレにくくなり、統計検定の分散が減って違反を検出しやすくなります。このように、まずは「ノイズ以外の要因で差が出る状況」を作るための引数設定を行います。

分岐差分を引き起こす制約生成 – 次に、残りの引数については、Mのソースコードを解析して「 $ D_1 $ の場合と $ D_2 $ の場合で異なる分岐をとる」ことを促進する制約を集めます。具体的には、 $ M$のプログラムをシンボリック実行ツールでトレースします。 $ D_1 $ と$D_2 $ は具体値として与え、その他の引数（例えば閾値 $ T$や他のフラグなど）をシンボリック変数として実行します。この際、 $ M$内部の乱数サンプルは全て固定値（例:0）に設定しておきます。これは、ノイズによる分岐の不確実性を除き、 $ D_1 $ と$D_2 $ の構造上の違いによる条件分岐のみを解析するためです。プログラム中のif文やループの条件を辿り、 $ D_1 $ を入力した場合に真・偽となる条件と、 $ D_2 $ を入力した場合に真・偽となる条件を比較します。もし特定の条件式で評価結果が $ D_1 $ と$D_2 $ で異なる（つまり片方は真、もう一方は偽）なら、その条件が指すパスの分岐で2つの実行が異なる経路を取ることになります。このような条件について、「その分岐の両側をそれぞれ実現するような引数設定を満たせ」という制約をシンボリック実行から取得します。平たく言えば、「 $ D_1 $ と$D_2 $ でできるだけ処理の流れが分かれるように引数を選べ」という制約群です。疎ベクトル法で言えば、閾値 $ T$の値によってどのクエリでTrue/Falseを返すかが決まり、その結果ループが早期終了するか否かなど分岐が変わります。そこで「ある $ T$では $ D_1 $ 上はTrueだが $ D_2 $ 上はFalseになるように」などの条件を列挙していくイメージです。

MaxSMTソルバによる充足解探索 – 手に入れた制約集合は、一般にはすべてを同時に満たすことが難しい場合があります。シンボリック実行で大量の分岐条件が見つかると、それら全てを矛盾なく実現する引数は存在しないかもしれません。そこで、MaxSMT（Maximum Satisfiability Modulo Theories）ソルバを用いて、できるだけ多くの制約を満たす解を探します。MaxSAT/MaxSMTとは、与えられた論理制約のうち充足可能な最大数の制約を満たす解を求める手法です。擬似コードでは args1 = MaxSMT(constraints) として、この制約充足問題を解いて得られた引数値の割当てを取得しています。これにより、「 $ D_1 $ と$D_2 $ で可能な限り多くの分岐が異なる」という目的が達成されます。分岐がたくさん異なるほど、一方の入力でTrueになる回数やFalseになる回数などプライバシー使用に関わる挙動に差が出る可能性が高く、結果として差分プライバシー違反が起きやすくなります。

引数の統合と返却 – 最終的に、ステップ1で決めたノイズ関連引数args0と、ステップ3で得られた引数args1とを統合して返します。例えばSVTなら、ノイズ規模に関わる $ N$は1に設定し（args0）、閾値 $ T$についてはMaxSMTで導かれた値（args1）を使う、といった具合に一つのargsにまとめます。

以上が ArgumentGenerator の流れです。InputGenerator（アルゴリズム4）は、前半(A)で用意した各データベース候補 $ (D_1, D_2) $ に対してこの ArgumentGenerator を適用し、得られたargsと組にして InputList に追加していきます。結果として、多数の $ (D_1, D_2, args) $ 候補が生成されます。Algorithm 1ではこの InputList を受け取り、前述の EventSelector へ渡すことで、最適な反例コンビネーションの探索へと進むわけです。

要するに、InputGeneration段階では一般的な入力変化のパターンを網羅しつつ、各アルゴリズム特有のパラメータはプライバシーコストを最大化しうる値に自動調整しています。プログラム解析（シンボリック実行）と論理ソルバ（MaxSMT）の力を借りている点でブラックボックステスト以上の知見を活用していますが、それでも対象アルゴリズムの内部実装に過度の制約は設けず、広範なアルゴリズムに適用可能な汎用性を保っています。

### 5. 実験評価: 各種アルゴリズムに対する検証

#### 概要

論文では、以下の主要アルゴリズムに対して正しい実装と既知の誤った実装の両方を評価:

1. **Noisy Max**: 複数クエリの最大値を差分プライベートに報告
2. **Histogram**: ヒストグラム公開アルゴリズム
3. **Sparse Vector Technique (SVT)**: 閾値判定を複数回行う疎ベクトル法

**評価方法**: テストε値に対するp値の推移をグラフ化。正しい実装では主張ε付近でp値が上昇（違反なし）、誤った実装ではp値が低いまま（違反検出）。

#### Noisy Maxに対する評価

Noisy Maxは、一連のクエリ回答 $ Q[i] $ の中から最大値のクエリを報告するアルゴリズムです。正しい差分プライバシー実装では各クエリ回答にラプラスノイズまたは指数ノイズを独立に加え、その中の最大値のインデックス（どのクエリが最大だったか）を返します。一方、誤った実装の例として、最大値そのもの（ノイズ付きの数値）を返してしまうものがあります。後者は一見些細な違いですが、実は出力空間が連続値に広がるためプライバシー予算の消費が増大し、正しいϵでは収まらなくなる既知のバグです。

提案手法による検定では、正しいNoisy Max実装（Laplace版およびExponential版）について、主張されたプライバシー予算ϵ₀（例えば0.2, 0.7, 1.5）を下回るテストϵでは容易に違反が検出されるが、ϵがϵ₀付近に達するとp値が上昇し違反のエビデンスが消えるという結果になりました。具体的に、ϵ₀=0.7の正実装をテストした場合、ϵ=0.6まではp値が極めて小さい（有意に違反を検出）が、ϵ≈0.7でグラフの線が跳ね上がりp値≈1に近づく様子が図2a,bに示されています。この挙動は理想的な結果と一致しており、ϵ₀未満では誤検知もなく、ϵ₀以上では違反を示さないことから、本ツールの検定精度の高さが示されています（点線が理論上の境界を示す）。

一方、誤ったNoisy Max（最大値そのものを返す実装）では、p値の挙動が明らかに異なりました。Laplaceノイズ版の誤実装では、例えばϵ₀=0.2に対しテストϵ≈0.4になってようやくp値が上昇しはじめ（違反が緩和される）という具合で、主張ϵ₀=0.2では全くプライバシー保証が守れていないことが検出されています。ϵ₀=0.7や1.5の場合に至っては、テストでϵを最大2.2程度まで上げてもなおp値≈0のままで線がほとんど描画されないほどであり、事実上「非常に大きなϵでなければプライバシー違反が解消されない」、すなわち実際のプライバシーコストが極めて高いことを示しています。図2c,dでは、誤実装に対する各ϵ₀の線が理論値よりはるか右側（大きなテストϵ側）で立ち上がっており、例えばϵ₀=1.5の場合はグラフ上ほぼ水平で違反し続けています。著者らは、この誤実装が実際には $ ϵ_0 \cdot |Q|/2 $ （|Q|はクエリ数）程度の差分プライバシー性しか持たないことを指摘しており、実験結果もそれを裏付けています。

検出された具体的反例として、例えば「Laplace版誤Noisy Max」では入力 $ D_1 $ を全クエリ値=1、 $ D_2 $ を全クエリ値=0にした場合に「出力が負の値になる」というイベントが違反の証拠として選ばれています。正しい実装なら出力はインデックス（1以上の整数）なので負になることはありませんが、誤実装ではノイズで負になる可能性があります。この**「 $ \omega < 0 $ 」**という事象 $ E$で $ P(M(D_1)\in E) $ が大きく異なり（ $ D_1 $ は常に最大値=1+ノイズなので負になる確率が小さいが、 $ D_2 $ は常に0+ノイズなので負になる確率が高い）、プライバシー違反が示されました。同様にExponential版誤Noisy Maxでも「 $ \omega < 1.0 $ 」という閾値イベントが選ばれています。これらは直観的にも、本来出力しないはずの異常値が出力されること自体が差分プライバシー破れに繋がっている例と言えます。

#### Histogramに対する評価

Histogramアルゴリズムは、データベースのヒストグラム（各カテゴリの出現数）にノイズを加えて公開するシンプルな手法です。入力は元のヒストグラム（固定長ベクトル）で、出力は同じ次元のノイズ付ヒストグラムです。正しい実装では各ビンに独立なLaplace(1/ϵ₀)ノイズを加えます。誤った実装例として、感度の扱いを間違えLaplace(ϵ₀)（分散が大きすぎる！※通常Lap(b)はbが小さいほどノイズ小）を加えてしまうケースが挙げられています。これは直感に反し「ϵ₀が小さいほどノイズが小さい」という設定になってしまい、実際には主張ϵ₀の逆数が真のプライバシー係数となります。例えばϵ₀=0.2なら本来は大きなノイズが必要なのに誤実装は極小ノイズしか加えず、結果「1/0.2=5-差分プライバシー」程度の弱い保証しかない、ということになります。

実験では、正しいHistogram実装についてNoisy Max同様、主張ϵ₀ごとに線グラフがϵ₀付近で立ち上がることが確認されました（図3a）。一方、誤実装ではϵ₀<1の場合に厳しい違反が検出されています。例えばϵ₀=0.2, 0.7では対応する真のプライバシー係数が5, ≈1.43と大きいため、図3bにてそれらの線はテストϵ=0.2, 0.7では全く上昇せず、はるか高いϵでようやく立ち上がる様子が示されています。実際、ϵ₀=0.2のケースではテストϵ≈0.6付近まで違反検出が続き、ϵ₀=0.7でも1を超えるϵでやっとp値が上がっています。これは期待通りで、誤実装の真のプライバシー保証はそれぞれ1/ϵ₀（=5や≈1.43）であり、ツールはその値より少し低いϵで違反を検出しなくなる（線が上がる）ことを確認できます。興味深いのはϵ₀=1.5の場合です。この場合真のプライバシー係数は2/3 ≈0.67と主張より小さく、つまりアルゴリズムは「過剰にプライバシーを守っている」状況になります。実験結果でも、ϵ₀=1.5の誤実装に対しテストϵ≈0.6で線が上昇しており、逆に言えば主張ϵ₀=1.5より厳しい0.6差分プライバシーすら守っている可能性を示唆しています。このように、本手法は誤実装が必ずしも「プライバシー漏れ過多」だけでなく「過剰なノイズで本来よりプライバシーが高い」ケースでも、その精度限界内で検出・評価できることが分かります。

実際に得られた反例の例では、「Laplace(ϵ₀)を使った誤Histogram」に対し、 $ D_1 $ を全ビン=1、 $ D_2 $ を一つのビンだけ2に増やした隣接ペアで**「出力ヒストグラムの最初のビンが1.0未満になる」**というイベントが選ばれています。これは、正しい実装なら最初のビンには平均1（元のカウント）±十分大きなノイズが乗るので0付近になる確率は適切ですが、誤実装ではノイズが小さいため $ D_2 $ （最初のビンが2）と $ D_1 $ （1）の出力分布がはっきり分かれ、特に $ D_2 $ では「出力<1」の確率が極小になる（元が2でノイズ小なので出力が1以上である場合が多い）といった違反が表れます。このように、Histogramのバグも確実に検出されています。

#### Sparse Vector Technique (SVT)に対する評価

**Sparse Vector Technique (SVT)**は、設定した閾値 $ T$に対し「入力クエリの値が上回っているか否か」を差分プライベートに逐次判定するアルゴリズムです。SVTの特徴は、閾値判定に関して「閾値以下であれば何度答えてもプライバシーコスト0」という点にあります。一方、閾値を超えた（Trueとなる）回答は高々 $ N$回までしか許されず、それ以上Trueを出すときは停止します。この性質により、許容回数 $ N$までのTrueと無制限のFalseを出力します。SVTは強力な手法ですが、その分実装も繊細で、多くの変種アルゴリズムが提案されては実は間違っていたと判明する事例が多数報告されています。論文では、正しいSVT実装（Lyuらによる証明済み実装 [28]）と、既知の主要な間違った実装（4種類、論文中ではiSVT1～4と呼称）をテストしています。

SVT 正実装 [28]: プライバシー予算ϵ₀を閾値用（η1のノイズ）とTrue値出力用（各η2のノイズ）に半分ずつ割り当て、Trueを $ N$回までしか出さないバージョンです。実験では、他の正実装と同様に、主張ϵ₀の値ごとに線がϵ₀付近で立ち上がり、ツールが「正しくプライバシーが守られている」ことを確認しています（図4aの各線はほぼϵ₀と同じ位置で上昇）。したがって、本手法はSVTのように複雑なアルゴリズムでも誤検出せず正確に動作しました。

iSVT 1 [38]: 閾値判定（η1）とクエリ値（η2）のどちらにもノイズを加えない、かつTrue出力回数に制限が無い最悪の変種です。もちろん差分プライバシーは全く成立せず、「有限のϵ₀ではどんな値でも満たさない」アルゴリズムです。本ツールでも、ϵ₀=0.2, 0.7, 1.5の各ケースでテストしたϵの範囲すべて（例えば0〜2.2まで）においてp値が0のまま上昇しない、つまり常に違反が検出された状態となりました（図4bは全ϵで線が下に張り付いている）。この結果は当然ですが、ツールが確実に「どんなϵでもアウトである」ことを示す反例を提示できたことを意味します。実際に選ばれた反例は、10長の入力で $ D_1 $ の全要素=1、 $ D_2 $ が半分0・半分2という組合せ（X Shapeの拡張）に対し**「出力がノイズ無し実行とまったく同じになる」（ $ t(\omega)=0 $ ）**というイベントでした。ノイズ皆無のため当たり前ですが、 $ D_1 $ と$D_2 $ で出力が異なる箇所が一切なくなる確率が極端に違い（ $ D_1 $ ではFalse連発、 $ D_2 $ ではTrueも出続け出力列が異なる）、即座にバレるというわけです。

iSVT 2 [11]: True出力の上限 $ N$が無制限である以外は正実装と同じ（ノイズはある）変種です。Trueを出し放題にすると、 $ N$に比例してプライバシー漏洩が累積するため、このアルゴリズムも有限ϵ₀ではプライバシーを満たしません。ツールの結果もiSVT1に近く、ϵ₀=0.2, 0.7, 1.5に対しそれぞれ「ϵ≈0.5まで」「ϵ≈2.1まで」「ϵ≈3.0まで」の範囲でp値が上がらない（違反し続けている）ことが確認されています。図4cでは例えばϵ₀=0.2の場合、テストϵ=0.5を超えてようやく線が上がり始めています。実際には上限なくTrueを出せると、理論的にはϵ→∞でしかプライバシー保証が成立しないため、ツールもかなり大きな範囲まで違反を検出し続けました。反例の例としては、iSVT2では $ D_1 $ と$D_2 $ に「前半1・後半0」vs「前半0・後半1」というX Shapeパターンを与え、イベントに** $ t(\omega)=9 $ **（10個中9箇所異なる出力）というものが選ばれています。True出力無制限のため、 $ D_2 $ （後半クエリが高いためTrueがたくさん出る）では出力列がほぼ $ D_1 $ （前半クエリ高い）とまったく異なる長さ/位置になることが多く、9箇所も相違が出るという極端な差が検出できたわけです。

iSVT 3 [27]: True上限 $ N$があるものの、各クエリへのノイズη2のスケールが誤って一定（ $ N$によらず）になっている変種です。本来は $ N$が大きいほど一つ一つのTrue判定で消費するプライバシー予算を小さくすべきですが、この実装ではそれをせず、結果として実際のプライバシーコストが $ (1+6N)/4 * ϵ₀ $ になると報告されています。例えば $ N=1 $ なら $ (1+6*1)/4=7/4=1.75 $ 倍、 $ N=2 $ なら $ (1+12)/4=13/4=3.25 $ 倍、などと肥大化します。ツールの結果は見事にこれを捉えており、図4dで各ϵ₀に対し理論値より少し手前で線が立ち上がっています。例えばϵ₀=0.2（ $ N=1 $ ）では真のプライバシー費用は0.35ですが、線は0.3付近で上昇し始めています。ϵ₀=0.7（理論1.225）の場合は線が1.1付近、ϵ₀=1.5（理論2.625）では2.3付近で上昇しています。いずれも過大なプライバシーコストを検出し、理論値の少し下（厳しめ側）で検出限界となっていることが示されています。つまり、本ツールは実装のバグによる「必要プライバシー予算の過小見積り」を具体的数値込みで指摘できたことになります。このケースの反例もiSVT2同様、X Shapeパターン入力に対し $ t(\omega)=0 $ （出力がノイズ無し実行と同じ）というイベントが検出されています。ノイズスケールが小さすぎるため、True/Falseの判定結果が常に決まりきってしまい、 $ D_1 $ と$D_2 $ で出力が全く同じになる（例えばどちらも最初のクエリだけTrueであとはFalse…等）確率が異常に高くなることを捉えたものと考えられます。

iSVT 4 [36]: Trueの場合に閾値を超えた実際のノイズ付き値（数値）を出力してしまう変種です。本来SVTはTrue/Falseのみ出力すべきですが、この実装はTrueのときに「 $ q_i + η2 $ の値そのもの」を返します。結果、出力がFalse/数値の混合列となり、Falseの個数や数値の大きさから追加の情報が漏れることになります。著者らは「任意の有限ϵ₀ではプライバシーを満たさない」ケースと述べています。しかしiSVT1や2と異なり、False/True自体の挙動はそこまで違わない（True回数も $ N$で制限されノイズもある）ため、非常に低い確率でのみ違反が発生する「ほぼ正しい」実装とされています。図4eでは線が他よりもノイズが多く見えますが、それでも各ϵ₀の線は主張より遅れて上昇しており、ϵ₀=0.2, 0.7, 1.5の全てでプライバシー破れを検出しています。ただしp値が極端に0に張り付くわけではなく、一部区間で0でない値も見られるため、違反の頻度がごく低いこともうかがえます。ツールはこのケースでも統計的に有意な違反を捉え、「ϵ₀差分プライバシーではない」ことを結論付けました。EventSelectorが選んだイベントは先述の通り「Falseが9回、最後の数値出力が(-2.4,2.4)に入る」という複合条件で、False/Trueの混合出力から情報を引き出す巧みなものです。 $ D_1 $ として全クエリ0、 $ D_2 $ として全クエリ0（常にFalseしか出ない）を与えれば、本来Trueは出ないはずですが、iSVT4ではノイズ値そのものを吐くせいでたまにFalseの代わりに0近辺の数値が漏れて出力されることがあり、それを検知した例と推察されます。

以上のように、Noisy Max, Histogram, SVTそれぞれの正しい実装では本ツールのp値グラフは理論通りの挙動を示し、誤った実装では著名なバグ（過小ノイズ、出力内容の誤り、回数制限の欠如等）に起因する差分プライバシー違反を全て検出できました。さらに、理論解析で判明していた「実際にはϵ₀を満たさないがϵ=Xなら満たす」といった境界値もグラフから読み取れる精度であり、反例として提示される $ (D_1, D_2, E) $ も人間がアルゴリズムの欠陥を理解しやすい形で出力されています。例えば表2（論文中のTable 2）に示された反例一覧では、前述のNoisy MaxやHistogram、SVT各バリアントに対し、それぞれ「 $ D_1 $ をこう、 $ D_2 $ をこうしたら、このイベントで違反」という具体例が列挙されています。本解説中でもいくつか触れた通り、簡潔な入力差分（1や0を用いた短いベクトル）と分かりやすいイベント条件（値が負になる、出力長が違う、等）が多く、開発者が見てもバグの所在を突きやすい内容になっています。

## 他手法との比較: StatDP vs DPEST

本セクションでは、StatDPと本プロジェクトで実装されているDPESTを、いくつかの代表的なアルゴリズムで比較します。データソースは `docs/privacy_loss_report.md` からの実験結果です。

### アプローチの根本的な違い

| 項目 | StatDP | DPEST |
|------|--------|-------|
| **手法分類** | サンプリングベース統計的検定 | 解析的/サンプリングベース確率分布計算 |
| **入力** | アルゴリズム実装（ブラックボックス） | アルゴリズム実装（要コンパイル） |
| **出力** | 違反検出 (p値) + 反例 $ (D_1, D_2, E) $ | ε推定値 + 誤差範囲 |
| **主要技術** | Fisher's Exact Test + 確率的変換 | FFTベース畳み込み + 確率分布変換 |
| **シンボリック実行** | あり（入力生成用） | なし |

### 代表的アルゴリズムでの比較

#### TruncatedGeometric (ε=0.12)

**DPEST結果** (`docs/privacy_loss_report.md`より):
- 推定ε: 0.1312
- 理論ε: 0.12
- 誤差: +0.0112 (+9.3%)
- 実行時間: 23.92秒
- モード: サンプリング

**StatDP結果** (論文より):
- 推定ε: 0.116
- 実行時間: 10秒

**考察**:
- DPESTは理論値に最も近い（誤差9.3%）
- StatDPはやや保守的（理論より低め）
- 実行時間: StatDP 10秒 < DPEST 23.92秒

#### PrefixSum (プライバシー違反ケース)

**DPEST結果**:
- 推定ε: inf
- 理論ε: 0.10
- 実行時間: 123.84秒
- 結論: プライバシー違反を検出

**StatDP結果** (論文より):
- 推定ε: 0.348-0.503 (有限値)
- 実行時間: 60-2040秒
- 結論: 違反を見逃す可能性あり

**考察**:
- DPESTは無限大のプライバシー損失を正しく検出
- StatDPは有限値を推定し、違反を見逃している
- この case では**DPESTの方が正確**

#### SVT系アルゴリズム

**SVT1 (ε=0.10)**:
- DPEST: 0.0920 (誤差 -8.0%), 276.45秒
- StatDP: 正しい実装として認識

**SVT3 (プライバシー違反, 理論ε=∞)**:
- DPEST: inf, 47.02秒 → **違反を正しく検出**
- StatDP: p値が小さい → **違反を正しく検出**

**SVT5 (プライバシー違反, 理論ε=∞)**:
- DPEST: inf, 24.79秒 → **違反を正しく検出**
- StatDP: (該当する iSVT 変種) → **違反を正しく検出**

### OneTimeRAPPOR (ε=0.80)

**DPEST結果**:
- 推定ε: 0.6005
- 理論ε: 0.80
- 誤差: -0.1995 (-24.9%)
- 実行時間: 0.01秒
- モード: 解析

**StatDP結果** (論文より):
- 推定ε: 0.600
- 実行時間: 60秒

**考察**:
- 両手法とも同じ推定値（0.600）
- DPESTは**6000倍高速**（0.01秒 vs 60秒）
- 解析モードの威力を実証

### 総合評価

| 観点 | StatDP の強み | DPEST の強み |
|------|--------------|-------------|
| **精度** | 複雑な条件下でも違反検出可能 | プライバシー違反（∞）の正確な検出 |
| **速度** | サンプリングベースで比較的高速 | 解析モードでは圧倒的に高速 |
| **反例生成** | 具体的な $ (D_1, D_2, E) $ を提供 ⭐ | 提供しない |
| **適用範囲** | 任意の実装（ブラックボックス） ⭐ | 要コンパイル（制約あり） |
| **違反検出** | 統計的証拠（p値） | 無限大検出が正確 ⭐ |
| **実用性** | 開発者が欠陥を理解しやすい ⭐ | 定量的なε推定値 ⭐ |

### 使い分けの指針

- **StatDPが適している場合**:
  - プライバシー違反の具体的な反例が欲しい
  - アルゴリズムのソースコードが利用可能（シンボリック実行用）
  - ブラックボックステストを行いたい
  - 実装のバグ箇所を特定したい

- **DPESTが適している場合**:
  - 定量的なε値の推定が必要
  - 極めて高速な検証が必要（解析モード利用時）
  - プライバシー違反（∞）の明確な検出が必要
  - 確率分布の詳細な解析が必要

### まとめ

本稿では「Detecting Violations of Differential Privacy」の提案手法（StatDP）について、アルゴリズム構成と統計手法を中心に詳細に説明しました。セミブラックボックスなアプローチにより、対象アルゴリズムを大量実行して統計的仮説検定を行うことで、証明負担なく自動的にプライバシー違反の反例を発見できる点が本手法の強みです。

一方、DPESTは確率分布の解析的計算により、特に解析モードでは極めて高速にε値を推定でき、プライバシー違反（ε=∞）の検出においてStatDPより正確な場合があることが分かりました。

両手法は相補的であり、用途に応じて使い分けることで、差分プライバシーアルゴリズムの実装検証をより効果的に行うことができます。