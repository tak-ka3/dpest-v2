# プライバシー損失（ε）の推定方法

## 概要

本ドキュメントでは、dpestフレームワークにおけるプライバシー損失パラメータ ε の推定方法について説明します。

### プライバシー損失とは

差分プライバシーにおけるプライバシー損失 ε は、隣接する2つのデータセット $D$ と $D'$ に対するアルゴリズム $M$ の出力分布がどの程度区別可能かを表す指標です。数学的には、2つの出力分布 $P$ と $Q$ の最大対数比として定義されます：

$$
\varepsilon = \max_{S \subseteq \text{Range}(M)} \ln \frac{P(M(D) \in S)}{Q(M(D') \in S)}
$$

この値が小さいほど、2つのデータセットの区別が困難であり、プライバシー保護が強いことを意味します。

### dpestの基本アプローチ

dpestは、差分プライバシーアルゴリズムのプライバシー損失を**数値的に推定**することを目的としています。理論的な証明による上界ではなく、アルゴリズムの出力分布を実際に計算することで、より正確なεの値を求めます。

推定プロセスは以下の2つの主要ステップから構成されます：

1. **出力分布の計算**: 隣接データセット $D$ と $D'$ それぞれに対して、アルゴリズムの出力分布 $P$ と $Q$ を計算します
2. **最大対数比の計算**: 2つの出力分布から、すべての可能な出力部分集合 $S$ に対する対数比の最大値を求めます

dpestの特徴は、この計算を2つの異なる手法—**解析手法**と**サンプリング手法**—で実現できる点にあります。アルゴリズムの構造（特に確率変数間の依存関係の有無）に応じて、適切な手法が自動的に選択されます。

---

## 詳細ステップ

### ステップ1: 隣接データセットの定義

プライバシー損失を推定するには、まず**隣接データセット**のペアを定義する必要があります。隣接データセットとは、1つまたは複数のレコードの値が異なる2つのデータセットを指します。

#### 隣接性の概念

差分プライバシーにおける隣接性には、主に2つの定義があります：

- **置換型隣接性（Substitution）**: データセットのサイズは同じで、1つのレコードの値が異なる
- **追加削除型隣接性（Add/Remove）**: 1つのレコードが追加または削除される

dpestでは、置換型隣接性をベースとした複数のパターンを提供しています。これらのパターンは `dpest.utils.input_patterns.generate_patterns()` 関数で生成できます。

#### 基本パターン

**one_above**: 最初のレコードの値を1つ増やします。これは最も基本的な隣接パターンであり、1つのレコードの値が上方向に変化した場合のプライバシー損失を測定します。

```python
D       = [1, 1, 1, 1, 1]
D_prime = [2, 1, 1, 1, 1]
```

**one_below**: 最初のレコードの値を1つ減らします。これはone_aboveと対称的なパターンで、値が下方向に変化した場合を評価します。

```python
D       = [1, 1, 1, 1, 1]
D_prime = [0, 1, 1, 1, 1]
```

#### 複合パターン

複合パターンは、複数のレコードが同時に変化する場合のプライバシー損失を評価するために用意されています。これらは、アルゴリズムが複数のレコードの変化にどのように反応するかを調べるのに有用です。

**one_above_rest_below**: 最初のレコードを増やし、残りを減らします：

```python
D       = [1, 1, 1, 1, 1]
D_prime = [2, 0, 0, 0, 0]
```

**one_below_rest_above**: 最初のレコードを減らし、残りを増やします：

```python
D       = [1, 1, 1, 1, 1]
D_prime = [0, 2, 2, 2, 2]
```

**half_half**: 前半のレコードを減らし、後半を増やします：

```python
D       = [1, 1, 1, 1, 1]
D_prime = [0, 0, 0, 2, 2]
```

**all_above_all_below**: すべてのレコードを増やします：

```python
D       = [1, 1, 1, 1, 1]
D_prime = [2, 2, 2, 2, 2]
```

**x_shape**: 前半と後半で値を入れ替えます：

```python
D       = [1, 1, 0, 0]
D_prime = [0, 0, 1, 1]
```

これらのパターンを使用することで、アルゴリズムのプライバシー損失を多角的に評価できます。

---

### ステップ2: 出力分布の計算

隣接データセットを定義したら、次はそれぞれのデータセットに対してアルゴリズムの出力分布を計算します。dpestは、この計算を2つの異なる方法で実現します。

#### 解析手法（Analytic Mode）

解析手法は、確率分布を**格子近似**により離散化し、数値計算によって演算を実行する方法です。この手法は、確率変数間に依存関係がない場合に使用できます。

**動作原理**:

連続確率分布（例：Laplace分布）を有限個の格子点で近似し、各演算（加算、アフィン変換、比較など）を格子上で実行します。例えば、2つの独立な確率変数の和は、FFT（高速フーリエ変換）を用いた畳み込みとして効率的に計算されます。

**適用条件**:

- すべての確率変数が互いに独立である
- Branch演算が存在しない、または条件と分岐先が独立である
- 複数の出力要素が共通の確率変数を参照しない

**特徴**:

- **決定論的**: 同じ入力に対して常に同じ結果が得られます
- **高精度**: 格子点数を増やすことで任意の精度を達成できます
- **独立性の制約**: 依存関係がある場合は適用できません

#### サンプリング手法（Sampling Mode）

サンプリング手法は、Monte Carlo法により確率分布から大量のサンプルを生成し、経験分布で近似する方法です。この手法は、依存関係を含むアルゴリズムに対しても適用できます。

**動作原理**:

アルゴリズムを実際に $N$ 回実行し、その出力のサンプルを収集します。これらのサンプルからヒストグラムを構築することで、出力分布を近似します。依存関係がある場合でも、同じ乱数シードを用いることで正しく依存構造を保持できます。

**適用条件**:

- 依存関係の有無に関わらず、すべてのアルゴリズムに適用可能
- 特にBranch演算で同じ確率変数を複数回参照する場合に必須
- SVT系アルゴリズムやPrefixSumのように、前の出力が次の出力に影響を与える場合に必要

**特徴**:

- **汎用性**: 任意の複雑な確率操作に対応できます
- **依存関係対応**: 確率変数間の依存関係を正確に扱えます
- **統計的誤差**: サンプル数 $N$ に依存する統計的誤差が発生します（$O(1/\sqrt{N})$）

#### モードの自動選択

dpestは、アルゴリズムの構造を解析し、適切な計算モードを自動的に選択します。具体的には：

1. アルゴリズム内でBranch演算が依存関係を持つ場合、サンプリングモードに切り替え
2. 複数の出力要素が共通の確率変数（例：共通のノイズ付き閾値）を参照する場合、サンプリングモードに切り替え
3. それ以外の場合は解析モードを使用

ユーザーは明示的にサンプル数を設定することもできます：

```python
from dpest.engine import set_sampling_samples
set_sampling_samples(1000000)  # 100万サンプル
```

---

### ステップ3: プライバシー損失の計算

2つの出力分布 $P$ と $Q$ が得られたら、それらの最大対数比を計算してプライバシー損失 ε を求めます。計算方法は出力の型（離散、連続、混合、ジョイント）によって異なります。

#### 単一出力の場合

アルゴリズムが単一の値を出力する場合（例：Laplace機構、Report Noisy Maxなど）、`epsilon_from_dist(P, Q)` 関数を使用します。

**離散分布の場合**:

出力が有限個の離散値を取る場合、各値 $v$ に対する確率 $P(v)$ と $Q(v)$ の比を計算します：

$$
\varepsilon = \max_v \ln \frac{P(v)}{Q(v)}
$$

実装では、両分布のアトム（点質量）をマージし、共通の値に対する確率を比較します。一方の確率がゼロの場合、その比は無限大となり、$\varepsilon = \infty$ を返します。

**連続分布の場合**:

出力が連続値を取る場合、格子上で密度比を計算します：

$$
\varepsilon = \max_i \ln \frac{f_P(x_i)}{f_Q(x_i)}
$$

ここで $x_i$ は格子点、$f_P(x_i)$ と $f_Q(x_i)$ はそれぞれの点での確率密度です。実装では、両分布を共通の格子に補間してから密度比を計算します。

**混合分布の場合**:

離散部分と連続部分の両方を含む分布の場合、それぞれの部分で最大対数比を計算し、全体の最大値を取ります。

#### ジョイント出力の場合（依存関係あり）

アルゴリズムが複数の値をベクトルとして出力し、それらの間に依存関係がある場合（例：SVT1の出力 $[0,1,1,0,...]$）、ジョイント分布として扱う必要があります。

**サンプリングモードの場合**:

サンプリングモードでは、各 `Dist` オブジェクトに共通のサンプル列（`_joint_samples`）が保存されています。これを利用してジョイント分布を推定します：

```python
from dpest.utils.privacy import epsilon_from_list_joint
epsilon = epsilon_from_list_joint(P_list, Q_list, hist_bins=100)
```

**推定プロセス**:

1. 各データセットから $N$ 個のジョイントサンプルを取得（shape: $N \times d$）
2. サンプルのユニークパターンを抽出
3. ユニークパターン数が少ない場合（$\leq$ `hist_bins`）:
   - 各パターン $\mathbf{v}$ の出現頻度から確率を推定：$\hat{P}(\mathbf{v}) = \frac{\text{count}_P(\mathbf{v})}{N}$
   - 各パターンで対数比を計算：$\ln \frac{\hat{P}(\mathbf{v})}{\hat{Q}(\mathbf{v})}$
4. ユニークパターン数が多い場合（$>$ `hist_bins`）:
   - 多次元ヒストグラム（`np.histogramdd`）を使用して確率密度を推定
   - 各ビンで対数比を計算

**注意点**:

ビン数が指数的に増加する場合（$\text{bins}^d > 10^6$）、計算が困難になります。この場合、dpestは各次元のマージナル分布でεを推定し、それらを合計する保守的な推定にフォールバックします。

#### ジョイント出力の場合（独立な要素）

複数の出力要素が互いに独立な場合（例：Parallel Composition）、各要素のεを個別に計算し、合成則を適用します：

```python
from dpest.utils.privacy import epsilon_from_list
epsilon = epsilon_from_list(P_list, Q_list)
```

並列合成の場合、全体のプライバシー損失は各要素の最大値となります：

$$
\varepsilon_{\text{total}} = \max_i \varepsilon_i
$$

---

### ステップ4: 結果の解釈

推定されたプライバシー損失 ε の値を解釈する際には、いくつかの重要な点を考慮する必要があります。

#### 有限のεが得られた場合

推定値が有限の場合、アルゴリズムは $\varepsilon$-差分プライバシーを（近似的に）満たしていると判断できます。この値を理論的な上界と比較することで、アルゴリズムの実際のプライバシー保証を評価できます。

**解析手法の場合**: 格子近似による数値誤差が含まれますが、格子点数を増やすことで誤差を任意に小さくできます。

**サンプリング手法の場合**: Monte Carlo法による統計的誤差が含まれます。サンプル数 $N$ を増やすことで誤差は $O(1/\sqrt{N})$ で減少します。

例えば、理論値 $\varepsilon = 0.1$ に対して推定値 $\varepsilon = 0.1012$ が得られた場合、これは数値誤差の範囲内であり、アルゴリズムが正しく実装されていることを示唆します。

#### 無限大のεが得られた場合

推定値が $\varepsilon = \infty$ となる場合、2つの可能性があります：

**1. アルゴリズムが差分プライバシーを満たさない**:

一部のアルゴリズム変種（例：SVT3, SVT5）は、理論的にもプライバシー損失が無限大となることが知られています。この場合、dpestは正しく無限大を検出しており、アルゴリズムが差分プライバシーを満たさないことを示しています。

**2. サンプリングモードでカバレッジが不足**:

出力空間が広いアルゴリズム（例：NumericalSVT, PrefixSum）では、サンプル数が不足すると、片方のデータベースでのみ観測されるパターンが存在し、**ゼロカウント問題**が発生します。この場合、確率比が計算できず、保守的に $\varepsilon = \infty$ が返されます。

この問題を解決するには：
- サンプル数を増やす（例：$N = 1,000,000$ から $N = 10,000,000$ へ）
- ヒストグラムのビン数を調整する
- 出力空間の次元を減らす、または適応的ビニングを使用する

無限大が真の無限大か、サンプリングの制約によるものかを判断するには、サンプル数を段階的に増やして推定値の変化を観察することが有効です。

---

## 実装例

### 例1: LaplaceMechanismのε推定

```python
from dpest.algorithms import laplace_vec
from dpest.utils.input_patterns import generate_patterns
from dpest.analysis import estimate_algorithm

# 隣接データセットペアを生成
patterns = generate_patterns(n=5)

# 各パターンでε推定
for name, (D, D_prime) in patterns.items():
    epsilon = estimate_algorithm(
        name=f"LaplaceMechanism_{name}",
        pairs=[(D, D_prime)],
        dist_func=getattr(laplace_vec, '_dist_func', laplace_vec),
        eps=0.1,
        n_samples=100000
    )
    print(f"{name}: ε = {epsilon:.4f}")
```

### 例2: SVT1のジョイントε推定

```python
from dpest.algorithms import svt1
from dpest.utils.input_patterns import generate_patterns
from dpest.analysis import estimate_algorithm

# 隣接データセットペアを生成
patterns = generate_patterns(n=10)

# SVT1用のパラメータ
svt_pairs = [
    (patterns['one_above'][0], patterns['one_above'][1]),
    (patterns['one_below'][0], patterns['one_below'][1]),
]

# SVT1の_dist_func属性を取得
dist_func = getattr(svt1, '_dist_func', svt1)

# ε推定（サンプリングモード）
epsilon = estimate_algorithm(
    name="SVT1",
    pairs=svt_pairs,
    dist_func=dist_func,
    eps=0.1,
    n_samples=1000000,
    extra=(5.0, 2),  # (threshold, cutoff)
    hist_bins=100
)

print(f"SVT1: ε = {epsilon:.4f}")
```

---

## まとめ

dpestによるプライバシー損失推定は、差分プライバシーアルゴリズムの理論的保証を数値的に検証する強力な手法です。本ドキュメントで説明した手順に従うことで、任意のアルゴリズムに対して以下が可能になります：

1. **隣接データセットの定義**: 複数のパターンを用いた多角的な評価
2. **出力分布の計算**: 解析手法またはサンプリング手法による正確な分布推定
3. **プライバシー損失の計算**: 離散、連続、ジョイント分布に対応した柔軟な計算
4. **結果の解釈**: 理論値との比較による実装の妥当性検証

特に重要なのは、dpestが依存関係の有無を自動的に判定し、適切な計算手法を選択する点です。これにより、ユーザーは複雑な実装の詳細を意識することなく、プライバシー損失の正確な推定を行うことができます。
